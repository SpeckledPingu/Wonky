{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import lancedb\n",
    "from openai import OpenAI\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from fuzzy_json import loads as fuzzy_loads\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Optional, Any\n",
    "\n",
    "def citation_hash(source_string: str, n_digits: int = 6) -> str:\n",
    "    hash_object = hashlib.sha256(source_string.encode())\n",
    "    hex_digest = hash_object.hexdigest()\n",
    "    hash_int = int(hex_digest, 16)\n",
    "    numeric_id = hash_int % (10**n_digits)\n",
    "    return f\"{numeric_id:0{n_digits}d}\"\n",
    "\n",
    "from sqlmodel import Field, Session, SQLModel, create_engine, select\n",
    "from sqlalchemy import and_, or_\n",
    "load_dotenv('env_var')"
   ],
   "id": "592711803d38edb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ExtractionDBDocument(SQLModel, table=True):\n",
    "    __tablename__ = \"extractions\"\n",
    "    p_key: Optional[int] = Field(default=None, primary_key=True)\n",
    "    id: str\n",
    "    citation: str\n",
    "    title: str\n",
    "    text: str\n",
    "    type: str\n",
    "    elements: str\n",
    "    chunks: str\n",
    "    document_ids: str\n",
    "    run_id: str | None = ''\n",
    "    additional_fields: str | None = None"
   ],
   "id": "69237f96d2956818",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "def call_llm(query, temperature=0.35, seed=42, model=\"gemma-3-12b-it-qat\"):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        seed=seed,\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "model = \"gemini-2.0-flash\"\n",
    "model = \"gemini-2.5-flash-lite-preview-06-17\"\n",
    "total_tokens = list()\n",
    "\n",
    "def call_llm_flash(query, temperature=0.1, seed=42, max_tokens=8193 ):\n",
    "    client = genai.Client(api_key=os.environ['GEMINI_API_KEY'])\n",
    "    retries = 3\n",
    "    time_delay = 15\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=model,\n",
    "                contents=[query],\n",
    "                config=types.GenerateContentConfig(\n",
    "                    max_output_tokens=max_tokens,\n",
    "                    temperature=temperature,\n",
    "                    seed=seed\n",
    "                )\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"Retries left: {retries - i}\")\n",
    "            time.sleep(time_delay)\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "    total_tokens.append({'prompt_tokens':response.usage_metadata.prompt_token_count,\n",
    "                         'completion_tokens':response.usage_metadata.candidates_token_count,\n",
    "                         'total_tokens':response.usage_metadata.total_token_count,\n",
    "                         'timestamp':datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")})\n",
    "\n",
    "    return response.text"
   ],
   "id": "5c2c1cee083843fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_folder = Path(os.environ['DATA_FOLDER'])\n",
    "project_folder = Path(os.environ['PROJECT_FOLDER'])\n",
    "database_folder = Path(os.environ['DATABASE_FOLDER'])\n",
    "index_folder = Path(os.environ['INDEX_FOLDER'])\n",
    "research_json_folder = project_folder.joinpath('research_json')\n",
    "\n",
    "document_database_name = \"documents.sqlite\"\n",
    "insight_db_sql = 'insights'\n",
    "search_result_table_sql = 'search_results'\n",
    "metadata_table_sql = 'documents'\n",
    "\n",
    "# db_path = database_folder.joinpath(document_database_name).absolute()\n",
    "# engine = create_engine(f'sqlite:///{db_path}')\n",
    "database_location = Path('/Users/jameslittiebrant/Data/Mycroft/databases')\n",
    "db_path = database_location.joinpath('documents.sqlite').absolute()\n",
    "engine = create_engine(f'sqlite:///{db_path}')\n",
    "\n",
    "# Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "index = lancedb.connect(index_folder)\n",
    "\n",
    "index_table = 'crs_reports'\n",
    "table = index.open_table(index_table)\n",
    "\n",
    "# index_sr_location = 'crs_reports'\n",
    "# table_sr_name = 'sections'\n",
    "# index_folder = project_folder.joinpath(f'indexes/{index_sr_location}')\n",
    "#\n",
    "# index_sr = lancedb.connect(index_folder)\n",
    "# table_sr = index_sr.open_table(table_sr_name)\n",
    "encoder_model = 'nomic-ai/nomic-embed-text-v1.5'\n",
    "device = 'mps'\n",
    "encoder = SentenceTransformer(encoder_model, device=device, trust_remote_code=True)\n",
    "\n",
    "citation_hash_length = 6\n",
    "insight_citation_prefix = 'INST_'\n",
    "\n",
    "with open('insight_prompts_update.json','r') as f:\n",
    "    prompts = json.load(f)\n",
    "\n",
    "insight_identification_prompt = prompts['insight_identification']\n",
    "insight_extraction_prompt = prompts['insight_extraction_instructions']\n",
    "\n",
    "run_id = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")"
   ],
   "id": "a7d5aa48c73184c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "prompts.keys()",
   "id": "8230a3cc50688b6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def convert_response_to_json(response_text: str) -> List[dict]:\n",
    "    '''\n",
    "\n",
    "    :param response_text: string response from the llm that only has json data either formatted with ```json...```, or ONLY json data\n",
    "    :return: list of extracted items\n",
    "    '''\n",
    "    json_re = re.compile(r'```json(.+?)```', flags=re.DOTALL)\n",
    "    if json_re.search(response_text):\n",
    "        json_text = json_re.search(response_text).group(1)\n",
    "    else:\n",
    "        json_text = response_text\n",
    "    response_json = fuzzy_loads(json_text)\n",
    "    return response_json\n",
    "\n",
    "def create_citation(item: dict, fields: List[str], prefix='INST_', number_of_digits=6):\n",
    "    citation_string = \"\"\n",
    "    for field in fields:\n",
    "        citation_string += f\" {field}: {item[field]}\"\n",
    "    citation_number = citation_hash(citation_string, n_digits=number_of_digits)\n",
    "    return f\"{prefix}{citation_number}\""
   ],
   "id": "587ce3b14d2d389",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ExtractionDocument(BaseModel):\n",
    "    id: str\n",
    "    citation: str\n",
    "    title: str\n",
    "    text: str\n",
    "    type: str\n",
    "    elements: List[str]\n",
    "    chunks: List[str]\n",
    "    document_ids: List[str]\n",
    "    run_id: str | None = ''\n",
    "    additional_fields: Any | None = None\n",
    "\n",
    "def format_sections_to_chunk(sections, separator='\\n\\n'):\n",
    "    text = list()\n",
    "    for section in sections:\n",
    "        if 'heading' in section.type:\n",
    "            heading_value = int(section.type.split('_')[1])\n",
    "            header_value = '#'*heading_value\n",
    "            section_text = f\"{header_value} {section.content.strip()}\".strip()\n",
    "        else:\n",
    "            section_text = f\"{section.content}\".strip()\n",
    "        citation = f\"\"\"<{section.document_id}_{section.chunk_position}__{section.intra_chunk_position}>\"\"\"\n",
    "        section_text = f\"{citation}\\n{section_text}\\n{citation}\"\n",
    "        text.append(section_text)\n",
    "    text = separator.join(text)\n",
    "    text_total_citation_start = f\"\"\"<{section.document_id}_{section.chunk_position}>\"\"\"\n",
    "    text_total_citation_end = f\"\"\"</{section.document_id}_{section.chunk_position}>\"\"\"\n",
    "\n",
    "    text = f\"{text_total_citation_start}\\n{text}\\n{text_total_citation_end}\"\n",
    "    return text\n",
    "\n",
    "def create_grounding_documents_section_cite(db_documents, search_results):\n",
    "    formatted_text = format_sections_to_chunk(db_documents)\n",
    "    document_id_hash = citation_hash(formatted_text, n_digits=10)\n",
    "    document_id = f\"DOC_{document_id_hash}\"\n",
    "    document = ExtractionDocument(\n",
    "        id=document_id,\n",
    "        citation=document_id,\n",
    "        title=search_results.title,\n",
    "        text=formatted_text,\n",
    "        type=\"grounding\",\n",
    "        elements=list(set([_element.id for _element in db_documents])),\n",
    "        chunks=sorted(list(set([str(_element.chunk_position) for _element in db_documents]))),\n",
    "        document_ids=list(set([str(search_results.document_id)])),\n",
    "        additional_fields={}\n",
    "    )\n",
    "    return document\n"
   ],
   "id": "a1f1515286c7cb14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_grounding_document(search_result):\n",
    "    results = list()\n",
    "    with (Session(engine) as session):\n",
    "        chunks = select(SectionDBModel).filter(\n",
    "            and_(\n",
    "                SectionDBModel.document_id==search_result.document_id,\n",
    "                SectionDBModel.id.in_(search_result.element_ids)\n",
    "            )\n",
    "        ).limit(100)\n",
    "        chunks = session.exec(chunks)\n",
    "        for row in chunks:\n",
    "            results.append(SectionDBModel.model_validate(row))\n",
    "    document = create_grounding_documents_section_cite(results, search_result)\n",
    "    return document"
   ],
   "id": "6d4188c761c0f0f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_batches(batch_items: List, batch_size: int, batch_flex: int = 1) -> List[dict]:\n",
    "    '''\n",
    "    Keeping this simple and easy to read\n",
    "    :param batch_items: A list of items that you want to batch\n",
    "    :param batch_size: How big the batch size is\n",
    "    :param batch_flex: At what divisor should be applied to the batch size be stepped down to avoid a batch of a single item\n",
    "        e.g. a batch size of 5 and the last batch is 2, then you will have two batches of 4 and 3. If 6 remain, then 3 and 3\n",
    "        This is future functionality to build in.\n",
    "    :return: list of batch items\n",
    "    '''\n",
    "    number_of_items = len(batch_items)\n",
    "    batches = list()\n",
    "    for start in range(0, number_of_items, batch_size):\n",
    "        batch = batch_items[start:start+batch_size]\n",
    "        batches.append(batch)\n",
    "    return batches"
   ],
   "id": "4fae7a3cb6bb4c52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def format_evidence(insight):\n",
    "    evidence = list()\n",
    "    if isinstance(insight['evidenceFor'],list):\n",
    "        for evidence_for in insight['evidenceFor']:\n",
    "            evidence.append(f\"\"\"**Evidence For Insight:**\n",
    "    *Description:* {evidence_for['description']}\n",
    "    *Details:* {evidence_for['details']}\n",
    "    *Methodology:* {evidence_for['methodology']}\n",
    "    *Source:* {evidence_for['source']}\"\"\")\n",
    "\n",
    "    if isinstance(insight['evidenceAgainst'], list):\n",
    "        for evidence_against in insight['evidenceAgainst']:\n",
    "            evidence.append(f\"\"\"**Evidence Against Insight:**\n",
    "    *Description:* {evidence_against['description']}\n",
    "    *Details:* {evidence_against['details']}\n",
    "    *Methodology:* {evidence_against['methodology']}\n",
    "    *Source:* {evidence_against['source']}\"\"\")\n",
    "    if evidence:\n",
    "        return '\\n'.join(evidence).strip()\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def format_reasoning(insight):\n",
    "    _reasoning = list()\n",
    "    if insight['reasoningFor'] != 'N/A':\n",
    "        _reasoning.append(f\"\"\"*Reasoning For Insight:* {insight['reasoningFor']}\"\"\")\n",
    "    if insight['reasoningAgainst'] != 'N/A':\n",
    "        _reasoning.append(f\"\"\"*Reasoning Against Insight:* {insight['reasoningAgainst']}\"\"\")\n",
    "    if _reasoning:\n",
    "        return '\\n'.join(_reasoning).strip()\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def format_strength(insight):\n",
    "    strength_assessment = insight['strength']\n",
    "    return f\"\"\"*Assessment:* {strength_assessment['assessment']}\n",
    "    *Confidence:* {strength_assessment['confidence']}\n",
    "    *Plausibility:* {strength_assessment['plausibility']}\"\"\"\n",
    "\n",
    "def format_implications(insight):\n",
    "    implications = insight['implications']\n",
    "    return f\"\"\"\n",
    "    *Insight Utility:* {implications['use']}\n",
    "        *If True:* {implications['ifTrue']}\n",
    "        *If False:* {implications['ifFalse']}\"\"\"\n",
    "\n",
    "def format_full_insight(insight):\n",
    "    evidence = format_evidence(insight)\n",
    "    reasoning = format_reasoning(insight)\n",
    "    strength_of_insight = format_strength(insight)\n",
    "    implications = format_implications(insight)\n",
    "\n",
    "    evidence_reasoning = list()\n",
    "    if reasoning:\n",
    "        evidence_reasoning.append(reasoning.strip())\n",
    "    if evidence:\n",
    "        evidence_reasoning.append(evidence.strip())\n",
    "    evidence_reasoning = '\\n'.join(evidence_reasoning)\n",
    "\n",
    "    insight_text = f\"\"\"*Insight Title:* {insight['insight_title']}\n",
    "*Insight Citation:* {insight['insight_citation']}\n",
    "*Source Citations:* {', '.join(insight['citations'])}\n",
    "*Insight Statement:* {insight['statement']}\n",
    "*Insight Explanation:* {insight['explanation']}\n",
    "{evidence_reasoning}\n",
    "*Insight Strength Assessment:* {strength_of_insight}\n",
    "*Implications:* {implications}\n",
    "\"\"\"\n",
    "    return insight_text.strip()"
   ],
   "id": "98f15535255317c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def format_insight_text(insight):\n",
    "    _insight_data = insight.insight_data\n",
    "    insight_statements = '\\n\\n'.join([_insight['statement'] for _insight in _insight_data])\n",
    "    related_citations = ', '.join(insight.related_citations)\n",
    "    insight_explanations = '\\n\\n'.join([_insight['explanation'] for _insight in _insight_data])\n",
    "    insight_text = f\"\"\"**Insight Name:** {insight.insight_name}\n",
    "**Insight Citation:** {insight.citation}\n",
    "**Insight Type:** {insight.insight_type}\n",
    "**Insight Synopsis:** {insight.insight_synopsis}\n",
    "**Insight Description:** {insight_statements}\n",
    "**Insight Explanation:** {insight_explanations}\n",
    "**Insight Source Citations:** {related_citations}\"\"\"\n",
    "    return insight_text"
   ],
   "id": "c0154ebb561d79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def extract_insights(insights: List,\n",
    "                     document: ExtractionDocument,\n",
    "                     batch_size: int = 5,\n",
    "                     temperature: float = 0.2,\n",
    "                     max_tokens: int = 10000) -> List[ExtractionDocument]:\n",
    "    insight_extraction_batches = list()\n",
    "    for i in range(0, len(insights), batch_size):\n",
    "        insight_extraction_batches.append(insights[i:i+batch_size])\n",
    "    print(\"Number of batches: \", len(insight_extraction_batches))\n",
    "\n",
    "    all_insights = list()\n",
    "    for batch in insight_extraction_batches:\n",
    "        insights_formatted = [format_insight(insight) for insight in batch]\n",
    "        insights_formatted = '\\n\\n'.join(insights_formatted)\n",
    "        insight_details_prompt = prompts['insight_extraction_instructions'].format(insights=insights_formatted,\n",
    "                                                                                 document=document.text)\n",
    "\n",
    "        insight_extraction = call_llm_flash(insight_details_prompt, temperature=temperature, max_tokens=max_tokens)\n",
    "        extracted_insights = convert_response_to_json(insight_extraction)\n",
    "        for extracted_insight in extracted_insights:\n",
    "            insight = ExtractionDocument(\n",
    "                id = extracted_insight['insight_citation'],\n",
    "                title=extracted_insight['insight_title'],\n",
    "                citation=extracted_insight['insight_citation'],\n",
    "                elements=extracted_insight['citations'],\n",
    "                text=format_full_insight(extracted_insight),\n",
    "                type='insight',\n",
    "                chunks=[],\n",
    "                document_ids=document.document_ids,\n",
    "                run_id=document.run_id,\n",
    "                additional_fields=extracted_insight\n",
    "            )\n",
    "            all_insights.append(insight)\n",
    "    return all_insights"
   ],
   "id": "7b0e031f4af70659",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def llm_identify_insights(document: ExtractionDocument, identification_prompt: str) -> str:\n",
    "    identification_prompt_formatted = identification_prompt.format(document=document.text)\n",
    "    identified_insights = call_llm_flash(identification_prompt_formatted, temperature=0.2, max_tokens=1000)\n",
    "    return identified_insights\n",
    "\n",
    "def process_identified_insights(identified_insights: str,\n",
    "                                document: ExtractionDocument,\n",
    "                                insight_citation_prefix: str = \"INST_\",\n",
    "                                insight_citation_hash_length: int = 6) -> List:\n",
    "\n",
    "    identified_insights_json = convert_response_to_json(identified_insights)\n",
    "    insights = list()\n",
    "    for _insight in identified_insights_json:\n",
    "        _insight['run_id'] = document.run_id\n",
    "        _insight['citation'] = create_citation(_insight,\n",
    "                                              fields=['insight_type','insight_name','insight_synopsis'],\n",
    "                                              prefix=insight_citation_prefix,\n",
    "                                              number_of_digits=insight_citation_hash_length)\n",
    "        _insight['type'] = 'insight'\n",
    "        insights.append(_insight)\n",
    "    return insights"
   ],
   "id": "29c2a17bfb236813",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def format_insight(insight):\n",
    "    return f\"\"\"*Insight Citation:* {insight['citation']}\\n*Insight Type:* {insight['insight_type']}\\n*Insight Name:* {insight['insight_name']}\\n*Insight Description:* {insight['insight_synopsis']}\\n*Found in:* {', '.join(insight['related_citations'])}\"\"\""
   ],
   "id": "c1d2126ead558511",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# from dataschemas import ChunkDBSchema, DocumentDBModel, SectionDBModel\n",
    "from datamodels import ChunkLanceModel, ChunkDBModel, SectionDBModel"
   ],
   "id": "9d7f5504faf6b384",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "research_path_id = '2025_07_12_13_18_05'",
   "id": "f1f47f6d6b533939",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"Rural Broadband Expansion for economic growth.\"\n",
    "query_vec = encoder.encode(query)"
   ],
   "id": "e7f3a10299b3b62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "search_results = table.search(query_vec).limit(5).to_list()\n",
    "search_results = [ChunkLanceModel(**result) for result in search_results]"
   ],
   "id": "3d765f5a86e4d95b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "grounding_documents = [create_grounding_document(search_result) for search_result in search_results]\n",
    "for document in grounding_documents:\n",
    "    document.run_id = run_id"
   ],
   "id": "28e85092cd0f6eeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Insight Extraction",
   "id": "e9f2806749c0310e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "search_insights = list()",
   "id": "de38a416e518bea5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for document in tqdm(grounding_documents):\n",
    "    insights = llm_identify_insights(document, prompts['insight_identification'])\n",
    "    insights = process_identified_insights(insights, document)\n",
    "    print(len(insights))\n",
    "    all_insights = extract_insights(insights, document, batch_size=6, temperature=0.2, max_tokens=10000)\n",
    "    search_insights.extend(all_insights)"
   ],
   "id": "74d8dd9811445c53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(search_insights), [len(_doc.text.split(' ')) for _doc in grounding_documents], sum([len(_doc.text.split(' ')) for _doc in grounding_documents])",
   "id": "77ba0f6214a4827",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "research_database_location = Path('/Users/jameslittiebrant/Data/Mycroft/databases')\n",
    "research_db_path = research_database_location.joinpath('research.sqlite').absolute()\n",
    "research_engine = create_engine(f'sqlite:///{research_db_path}')"
   ],
   "id": "641f54eb474bafb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "SQLModel.metadata.create_all(research_engine)",
   "id": "247277ac97c156df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def prep_extraction_for_insert(extraction):\n",
    "    extraction = extraction.model_dump()\n",
    "    extraction['elements'] = '|'.join(extraction['elements'])\n",
    "    extraction['chunks'] = '|'.join(extraction['chunks'])\n",
    "    extraction['document_ids'] = '|'.join(extraction['document_ids'])\n",
    "    extraction['additional_fields'] = json.dumps(extraction['additional_fields'])\n",
    "    return extraction"
   ],
   "id": "38b049f52a760def",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "[len(_doc.text.split(' ')) for _doc in search_insights], sum([len(_doc.text.split(' ')) for _doc in search_insights])",
   "id": "43f01f4e039c6fac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "to_insert = [prep_extraction_for_insert(_extraction) for _extraction in search_insights]",
   "id": "a3ea798a10526d36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with Session(research_engine) as session:\n",
    "    session.bulk_insert_mappings(ExtractionDBDocument, to_insert)\n",
    "    session.commit()"
   ],
   "id": "b8ed0f7432c028be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "engine.dispose()",
   "id": "e14ab7253fbcfeea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "research_engine.dispose()",
   "id": "209ee275e8a2ee48",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "42e3e7148c713c69",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
