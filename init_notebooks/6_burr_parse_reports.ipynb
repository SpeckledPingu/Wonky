{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-15T23:01:00.871304Z",
     "start_time": "2025-04-15T23:00:58.624053Z"
    }
   },
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import lancedb\n",
    "from lancedb.rerankers import LinearCombinationReranker, RRFReranker\n",
    "from openai import OpenAI\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv('env_var')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T23:01:00.891850Z",
     "start_time": "2025-04-15T23:01:00.873899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "def call_llm(query, temperature=0.3, seed=42, model=\"gemma-3-4b-it@Q8_0\"):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        seed=seed,\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "model = \"gemini-2.0-flash\"\n",
    "total_tokens = list()\n",
    "\n",
    "def call_llm_flash(query, temperature=0.1, seed=42, max_tokens=2000 ):\n",
    "    client = genai.Client(api_key=os.environ['GEMINI_API_KEY'])\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=[query],\n",
    "        config=types.GenerateContentConfig(\n",
    "            max_output_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            seed=seed\n",
    "        )\n",
    "    )\n",
    "    total_tokens.append({'prompt_tokens':response.usage_metadata.prompt_token_count,\n",
    "                         'completion_tokens':response.usage_metadata.candidates_token_count,\n",
    "                         'total_tokens':response.usage_metadata.total_token_count,\n",
    "                         'timestamp':datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")})\n",
    "\n",
    "    return response.text"
   ],
   "id": "e5875410c379802b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T23:01:00.908768Z",
     "start_time": "2025-04-15T23:01:00.895651Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from burr.core import action, State, ApplicationBuilder, ApplicationContext, Action\n",
    "from burr.core.parallelism import MapStates, RunnableGraph"
   ],
   "id": "851d0a714c65211f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T23:01:00.930589Z",
     "start_time": "2025-04-15T23:01:00.912558Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext burr.integrations.notebook\n",
    "%burr_ui"
   ],
   "id": "e62a9ac04c694298",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1767f9450>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://127.0.0.1:7241\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T23:01:00.938816Z",
     "start_time": "2025-04-15T23:01:00.937125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parsing_prompt = \"\"\"I have a document that's written in markdown. I want to split it into the main sections so that I can organize the different sections, and have a summary for the whole document that I can reference later on. I need you to provide the text that I can split the document on. That text should be the title or beginning of each major section.\n",
    "If a section is the title of the document, prefix the string with \"DOCUMENT TITLE:\" so that I know it's not a section title. If it is a major section, prefix it with \"SECTION #:\" where the section number is a number that increments up from 1 to number the sections. If the document has an overall summary or conclusion for the entire document, provide that as an additional section.\n",
    "If there is no summary, then the summary you write should be a paragraph or two at most and capture the main points about the document.\n",
    "\n",
    "Structure your response with the following sections and formatting:\n",
    "\n",
    "DOCUMENT_TITLE: [document title]\n",
    "SECTION #:\n",
    "SECTION #:\n",
    "...\n",
    "SUMMARY:\n",
    "\n",
    "Here is my document:\n",
    "{report}\"\"\""
   ],
   "id": "728a6b7259035785",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T23:01:03.509523Z",
     "start_time": "2025-04-15T23:01:00.942552Z"
    }
   },
   "cell_type": "code",
   "source": "encoder = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', device='mps',trust_remote_code=True)",
   "id": "8bc3dd37298ac51d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "!!!!!!!!!!!!megablocks not available, using torch.matmul instead\n",
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T23:01:03.516646Z",
     "start_time": "2025-04-15T23:01:03.514317Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_report_to_sections(report, section_markers):\n",
    "    parsed_document = list()\n",
    "    split_document = report.split('\\n')\n",
    "\n",
    "    current_section_idx = 0\n",
    "    current_section_marker = section_markers[current_section_idx]\n",
    "    current_section = [split_document[0]]\n",
    "\n",
    "    for line_number, line in enumerate(split_document):\n",
    "        if current_section_marker[1].lower() in line.lower():\n",
    "            if line_number != 0:\n",
    "                parsed_document.append('\\n'.join(current_section))\n",
    "            # current_section = list()\n",
    "            current_section_idx += 1\n",
    "            current_section = [line]\n",
    "            if current_section_idx < len(section_markers):\n",
    "                current_section_marker = section_markers[current_section_idx]\n",
    "            continue\n",
    "        else:\n",
    "            current_section.append(line)\n",
    "    parsed_document.append('\\n'.join(current_section))\n",
    "    return parsed_document"
   ],
   "id": "b2ddc12df7b70a52",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T23:01:03.521941Z",
     "start_time": "2025-04-15T23:01:03.520236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_report(report, section_markers):\n",
    "    parsed_document = parse_report_to_sections(report, section_markers)\n",
    "    segmented_report = list()\n",
    "    section_idx = 1\n",
    "    for marker, section in zip(section_markers, parsed_document):\n",
    "        segmented_report.append({'section_idx': section_idx,\n",
    "                                 'section_id':marker[0],\n",
    "                                 'section_title':marker[1],\n",
    "                                 'section_text':section})\n",
    "        section_idx += 1\n",
    "    return segmented_report"
   ],
   "id": "4e868433239906a2",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T23:02:29.070291Z",
     "start_time": "2025-04-15T23:02:29.062563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@action(reads=[], writes=[\"report_data\", \"file_name\", \"file_path\"])\n",
    "def load_report_from_file(state: State, file_path: Path):\n",
    "    with open(file_path,'r') as f:\n",
    "        report_data = json.load(f)\n",
    "\n",
    "    return state.update(report_data=report_data,\n",
    "                        file_path=str(file_path),\n",
    "                        file_name=str(file_path.name))\n",
    "\n",
    "@action(reads=[\"report_data\"], writes=[\"report\",\"section_markers\", \"parsing_prompt\",\"summary\"])\n",
    "def llm_segment_and_summarize(state: State) -> State:\n",
    "    report = state['report_data']['report']\n",
    "    formatted_parsing_prompt = parsing_prompt.format(report=report)\n",
    "    sections_and_summary = call_llm_flash(formatted_parsing_prompt)\n",
    "    document_title = re.search(r\"DOCUMENT_TITLE: (.+?)\\n\", sections_and_summary).group(1)\n",
    "    document_summary = re.search(r\"SUMMARY:\\s+(.+)\", sections_and_summary, flags=re.DOTALL | re.MULTILINE).group(1).strip('`')\n",
    "    section_numbers = re.findall(r\"SECTION (\\d+): (.+?)\\n\", sections_and_summary)\n",
    "    section_markers = [('title', document_title)] + section_numbers\n",
    "    return state.update(report=report, section_markers=section_markers, parsing_prompt=formatted_parsing_prompt, summary=document_summary)\n",
    "\n",
    "@action(reads=[\"report\",\"report_data\",\"section_markers\",\"summary\"], writes=[\"parsed_document\"])\n",
    "def parse_report_to_segments(state: State) -> State:\n",
    "    report = state['report']\n",
    "    segments = state['section_markers']\n",
    "    report_data = state['report_data']\n",
    "    parsed_document = parse_report(report, segments)\n",
    "    parsed_data = {\n",
    "        \"sections\":parsed_document,\n",
    "        \"report\":report_data['report'],\n",
    "        \"summary\":state['summary'],\n",
    "        \"topic\":report_data['topic'],\n",
    "        \"focus\":report_data['focus'],\n",
    "        \"relevant_citations\":report_data['relevant_citations'],\n",
    "        \"source_file\":state['file_path'],\n",
    "        \"source_file_name\":state['file_name']\n",
    "    }\n",
    "    return state.update(parsed_document=parsed_data)\n",
    "\n",
    "@action(reads=[\"parsed_document\"], writes=[\"parsed_document\"])\n",
    "def encode_text(state: State) -> State:\n",
    "    parsed_document = state['parsed_document']\n",
    "    for section in parsed_document['sections']:\n",
    "        section['section_vector'] = encoder.encode(section['section_text']).tolist()\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "    parsed_document['report_vector'] = encoder.encode(parsed_document['report']).tolist()\n",
    "    torch.mps.empty_cache()\n",
    "    parsed_document['summary_vector'] = encoder.encode(parsed_document['summary']).tolist()\n",
    "    torch.mps.empty_cache()\n",
    "    return state.update(parsed_document=parsed_document)"
   ],
   "id": "94ba4f81911bf5bf",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T23:07:26.268497Z",
     "start_time": "2025-04-15T23:07:26.266097Z"
    }
   },
   "cell_type": "code",
   "source": "project_name = \"south_america_research_topics\"",
   "id": "995033dc5242dcc",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T23:07:26.448530Z",
     "start_time": "2025-04-15T23:07:26.444784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "source_folder = Path('wonky_data/data/research_data')\n",
    "project_folder = source_folder.joinpath(project_name)\n",
    "reports = list(project_folder.glob('*.json'))\n",
    "save_folder = Path('wonky_data/data/processed_research')\n",
    "save_folder = save_folder.joinpath(project_name)\n",
    "save_folder.mkdir(parents=True, exist_ok=True)\n",
    "reports"
   ],
   "id": "26b2d2151c8f97ec",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('wonky_data/data/research_data/south_america_research_topics/the_geopolitics_of_environmental_issues_deforestation_climate_20250415151425.json'),\n",
       " PosixPath('wonky_data/data/research_data/south_america_research_topics/the_influence_of_external_actors_and_shifting_20250415151555.json'),\n",
       " PosixPath('wonky_data/data/research_data/south_america_research_topics/the_evolving_dynamics_of_regional_integration_and_20250415151143.json'),\n",
       " PosixPath('wonky_data/data/research_data/south_america_research_topics/the_rise_of_populism_and_political_polarization_20250415151311.json'),\n",
       " PosixPath('wonky_data/data/research_data/south_america_research_topics/the_impact_of_resource_nationalism_and_commodity_20250415151009.json')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T23:07:42.303240Z",
     "start_time": "2025-04-15T23:07:27.074423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for report_file in reports:\n",
    "    parsing_app = (\n",
    "        ApplicationBuilder()\n",
    "        .with_actions(\n",
    "            load_report_from_file,\n",
    "            llm_segment_and_summarize,\n",
    "            parse_report_to_segments,\n",
    "            encode_text\n",
    "        )\n",
    "        .with_transitions(\n",
    "            (\"load_report_from_file\", \"llm_segment_and_summarize\"),\n",
    "            (\"llm_segment_and_summarize\", \"parse_report_to_segments\"),\n",
    "            (\"parse_report_to_segments\", \"encode_text\"))\n",
    "        .with_entrypoint(\"load_report_from_file\")\n",
    "        .with_tracker(\n",
    "            \"local\",\n",
    "            project=f\"research_batch-parsing-{report_file.stem[:25]}\",\n",
    "        )\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    parsing_action, parsing_result, parsing_state = parsing_app.run(\n",
    "        halt_after=[\"encode_text\"],\n",
    "        inputs={\n",
    "            \"file_path\": report_file\n",
    "        }\n",
    "    )\n",
    "\n",
    "    with open(save_folder.joinpath(f'{report_file.name}'), 'w') as f:\n",
    "        json.dump(parsing_state['parsed_document'], f)"
   ],
   "id": "5a16b7124131912f",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2599c6442b122bb1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
