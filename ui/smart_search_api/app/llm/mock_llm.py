from typing import List
from app import schemas, models
from app.llm.base import LLMService
import random


class MockLLMService(LLMService):
    """
    A mock implementation of the LLMService that returns hardcoded text for testing.
    """
    
    def generate_summary_for_document(self, document: models.Document, guiding_prompt: str) -> str:
        print(f"[MockLLM] Generating summary for '{document.id}' with prompt: '{guiding_prompt}'")
        # Simulate LLM generation
        summary = f"Based on your prompt, a key point from '{document.title}' is its focus on {random.choice(['economic policy', 'technological impact', 'social implications'])}."
        return summary
    
    def generate_report_from_documents(self, documents: List[models.Document],
                                       job_request: schemas.ProcessingJobRequest) -> str:
        print(f"[MockLLM] Generating report for {len(documents)} documents.")
        doc_titles = [doc.title for doc in documents]
        
        # Simulate LLM report generation
        report_content = f"""
# Analysis Report: {job_request.analysisType.title()}

**Guiding Prompt:** *{job_request.prompt}*

This report was generated based on an analysis of the following source documents:
- {', '.join(doc_titles)}

## Mock Generated Content

This is a mock analysis generated by the LLM service. The primary theme identified across the selected documents is the critical role of data in modern decision-making. Further analysis, guided by a more specific prompt, would be required to extract more granular insights. For example, a comparative analysis could highlight differing policy recommendations between sources.
"""
        return report_content.strip()
