{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import lancedb\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import time\n",
    "load_dotenv('env_var')\n",
    "\n",
    "import wikipediaapi\n",
    "import wikipedia\n",
    "from burr.core import action, State, ApplicationBuilder, ApplicationContext, Action\n",
    "from burr.core.parallelism import MapStates, RunnableGraph\n",
    "\n",
    "from working_folder.workflows.topic_trend_research.processes.report_prompts import trend_report_prompt, follow_up_prompt, follow_up_query_prompt, \\\n",
    "                                                                                executive_summary_prompt\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia(user_agent='Wonky', language='en')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext burr.integrations.notebook\n",
    "%burr_ui"
   ],
   "id": "3c10e7eacc7ff990",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# index = lancedb.connect('../wonky_data/indexes/')\n",
    "# table = index.open_table('sections_hybrid')\n",
    "# encoder = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', device='mps', trust_remote_code=True)"
   ],
   "id": "a159edfbc96165ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "base_folder = Path('../wonky_data/')\n",
    "index_folder = base_folder.joinpath('indexes')\n",
    "\n",
    "# db = lancedb.connect(index_folder)\n",
    "# report_tbl = db.open_table(\"reports\")\n",
    "# section_tbl = db.open_table(\"reports_section\")"
   ],
   "id": "91487cfa0597d0e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "def call_llm(query, temperature=0.3, seed=42, model=\"gemma-3-4b-it@Q8_0\"):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        seed=seed,\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "model = \"gemini-2.0-flash\"\n",
    "total_tokens = list()\n",
    "\n",
    "def call_llm_flash(query, temperature=0.1, seed=42, max_tokens=7500 ):\n",
    "    client = genai.Client(api_key=os.environ['GEMINI_API_KEY'])\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=[query],\n",
    "        config=types.GenerateContentConfig(\n",
    "            max_output_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            seed=seed\n",
    "        )\n",
    "    )\n",
    "    total_tokens.append({'prompt_tokens':response.usage_metadata.prompt_token_count,\n",
    "                         'completion_tokens':response.usage_metadata.candidates_token_count,\n",
    "                         'total_tokens':response.usage_metadata.total_token_count,\n",
    "                         'timestamp':datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")})\n",
    "\n",
    "    return response.text"
   ],
   "id": "884044fd0c13224d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from copy import deepcopy\n",
    "class ParseWikipediaSections():\n",
    "    def __init__(self):\n",
    "        self.parsed_sections = list()\n",
    "        self.current_hierarchy = {'level_0':'', 'level_1':'', 'level_2':'', 'level_3':'', 'level_4':''}\n",
    "\n",
    "    def _recursive_extract(self, sections, level=0):\n",
    "        for s in sections:\n",
    "            # print(\"%s: %s - %s\" % (\"*\" * (level + 1), s.title, s.text[0:40]))\n",
    "            hierarchy_string = list()\n",
    "            for i in range(0,5):\n",
    "                if i == level:\n",
    "                    self.current_hierarchy[f\"level_{i}\"] = s.title\n",
    "                elif i > level:\n",
    "                    self.current_hierarchy[f\"level_{i}\"] = ''\n",
    "\n",
    "            for i in range(0,5):\n",
    "                _hierarchy_header = self.current_hierarchy[f\"level_{i}\"]\n",
    "                if _hierarchy_header != \"\":\n",
    "                    hierarchy_string.append(_hierarchy_header)\n",
    "            hierarchy_string = '|'.join(hierarchy_string)\n",
    "\n",
    "            self.parsed_sections.append({\"level\": level,\n",
    "                                         \"title\": s.title,\n",
    "                                         \"text\": s.text,\n",
    "                                         \"hierarchy\": deepcopy(self.current_hierarchy),\n",
    "                                         \"hierarchy_string\": hierarchy_string})\n",
    "\n",
    "            self._recursive_extract(s.sections, level + 1)\n",
    "\n",
    "    def parse_wikipedia_sections(self, sections):\n",
    "        self._recursive_extract(sections, level=0)\n",
    "        return self.parsed_sections\n",
    "\n",
    "def get_wikipedia_data(page_name):\n",
    "    wikipedia_page = wiki_wiki.page(page_name)\n",
    "    wikipedia_parser = ParseWikipediaSections()\n",
    "    parsed_sections = wikipedia_parser.parse_wikipedia_sections(wikipedia_page.sections)\n",
    "    wikipedia_data = {'title': wikipedia_page.title,\n",
    "                      'url': wikipedia_page.fullurl,\n",
    "                      'sections': parsed_sections}\n",
    "    return wikipedia_data\n",
    "\n",
    "def search_wikipedia_page(query, num_results=10):\n",
    "    wiki_wiki = wikipediaapi.Wikipedia(user_agent='Wonky', language='en')\n",
    "    search_results = wikipedia.search(query, results=num_results, suggestion=False)\n",
    "    print(search_results)\n",
    "    wikipedia_page_results = list()\n",
    "    for search_result in search_results:\n",
    "        wikipedia_page = wiki_wiki.page(search_result)\n",
    "        wikipedia_parser = ParseWikipediaSections()\n",
    "        parsed_sections = wikipedia_parser.parse_wikipedia_sections(wikipedia_page.sections)\n",
    "        try:\n",
    "            wikipedia_data = {'title': wikipedia_page.title,\n",
    "                              'url': wikipedia_page.fullurl,\n",
    "                              'sections': parsed_sections,\n",
    "                              'full_text': wikipedia_page.text}\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        wikipedia_page_results.append(wikipedia_data)\n",
    "        time.sleep(1)\n",
    "    return wikipedia_page_results\n",
    "\n",
    "def format_sections_w_citations(wiki_document, base_citation):\n",
    "    first_section = wiki_document[0]\n",
    "    current_level_1_idx = 1\n",
    "    current_level_2_idx = 1\n",
    "    current_level_1_name = first_section['hierarchy']['level_0']\n",
    "    current_level_2_name = first_section['hierarchy']['level_1']\n",
    "    formatted_sections = list()\n",
    "    first_section['citation'] = f\"{base_citation}({current_level_1_idx})({current_level_2_idx})\"\n",
    "    formatted_sections.append(first_section)\n",
    "    if len(wiki_document) > 1:\n",
    "        for section in wiki_document[1:]:\n",
    "            # if current_level_1_name == '':\n",
    "            #     current_level_1_name = section['hierarchy']['level_0']\n",
    "            # if current_level_2_name == '':\n",
    "            #     current_level_2_name = section['hierarchy']['level_1']\n",
    "            #     current_level_2_idx = 1\n",
    "\n",
    "            if current_level_1_name != section['hierarchy']['level_0']:\n",
    "                current_level_1_name = section['hierarchy']['level_0']\n",
    "                current_level_2_name = section['hierarchy']['level_1']\n",
    "                current_level_1_idx += 1\n",
    "                current_level_2_idx = 1\n",
    "                print(current_level_1_name)\n",
    "            elif (current_level_1_name == section['hierarchy']['level_0']) and (current_level_2_name != section['hierarchy']['level_1']):\n",
    "                current_level_2_name = section['hierarchy']['level_1']\n",
    "                current_level_2_idx += 1\n",
    "            else:\n",
    "                current_level_2_idx += 1\n",
    "\n",
    "            section['citation'] = f\"{base_citation}({current_level_1_idx})({current_level_2_idx})\"\n",
    "            print(section['citation'])\n",
    "            formatted_sections.append(section)\n",
    "            # current_level_1_idx += 1\n",
    "            # current_level_2_idx = 1\n",
    "    return formatted_sections"
   ],
   "id": "e8791ccfe2e010eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "report_folder = Path('wonky_data/data/research_data')\n",
    "report_file_name = \"rural broadband in america_20250416150226.json\"\n",
    "research = [report_folder.joinpath(report_file_name)]\n",
    "# research_project = 'south_america_research_topics'\n",
    "# report_folder = report_folder.joinpath(research_project)\n",
    "# research = list(report_folder.glob('*.json'))\n",
    "\n",
    "context_folder = Path('wonky_data/data/context_research')\n",
    "context_file = [context_folder.joinpath(report_file_name)]\n",
    "research, context_file"
   ],
   "id": "ff636a64d3ead10f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(research[0],'r') as f:\n",
    "    research_data = json.load(f)\n",
    "\n",
    "with open(context_file[0],'r') as f:\n",
    "    context_data = json.load(f)"
   ],
   "id": "7450d25442000233",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "af9953ad0a0f6e47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Burr Outline\n",
    "\n",
    "1. Load the data based on a source file\n",
    "2. Create the trend analysis report\n",
    "3. Create the follow up document for additional context\n",
    "4. Vectorize the wikipedia search results and index them\n",
    "5. Search for the relevant wikipedia articles\n",
    "6. Format the returned wikipedia sections\n",
    "7. Extract new information from wikipedia\n",
    "8. Create new wikipedia trend report\n",
    "9. Merge wikipedia trend reports\n",
    "10. Create an executive summary"
   ],
   "id": "6bfaf60eef5373dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "@action(reads=[], writes=[\"report_data\", \"file_name\", \"file_path\"])\n",
    "def load_report_from_file(state: State, file_path: Path) -> State:\n",
    "    with open(file_path,'r') as f:\n",
    "        report_data = json.load(f)\n",
    "\n",
    "    return state.update(report_data=report_data,\n",
    "                        file_path=str(file_path),\n",
    "                        file_name=str(file_path.name))\n",
    "\n",
    "@action(reads=[\"report_data\"], writes=[\"trend_report\"])\n",
    "def create_trend_analysis(state: State, topic: str, focus:str) -> State:\n",
    "    formatted_prompt = trend_report_prompt.format(topic=topic, focus=focus, report_data=state['report_data'])\n",
    "    trend_report = call_llm(formatted_prompt)\n",
    "\n",
    "    return state.update(trend_report=trend_report)\n",
    "\n",
    "@action(reads=[\"trend_report\"], writes=[\"follow_up_report\"])\n",
    "def create_search_follow_up_document(state: State, topic: str, focus: str) -> State:\n",
    "    formatted_prompt = follow_up_prompt.format(topic=topic, focus=focus, trend_report=state['trend_report'])\n",
    "    follow_up_report = call_llm(formatted_prompt)\n",
    "    return state.update(follow_up_report=follow_up_report)\n",
    "\n",
    "@action(reads=[\"follow_up_report\"], writes=[\"follow_up_sources\"])\n",
    "def search_wikipedia(state: State) -> State:\n",
    "    follow_ups = dict()\n",
    "    for section, follow_ups in state['follow_up_report'].items():\n",
    "        formatted_follow_up_prompt = follow_up_query_prompt.format(topic=section, focus=section, trend_report=state['trend_report'],\n",
    "                                                             follow_up=follow_ups)\n",
    "        query = call_llm(formatted_follow_up_prompt)\n",
    "        results = search_wikipedia_page(query, num_results=10)\n",
    "\n",
    "        follow_ups[section] = results\n",
    "\n",
    "    return state.update(follow_up_sources=follow_ups)\n",
    "\n",
    "@action(reads=[\"follow_up_sources\"], writes=[\"temp_index\"])\n",
    "def vectorize_and_index_wikipedia(state: State, temp_index_path: Path) -> State:\n",
    "    # magic here to create temporary database\n",
    "\n",
    "    # create the full document index\n",
    "\n",
    "    # create the section level index\n",
    "\n",
    "    return state.update(temp_index = temp_index_path)\n",
    "\n",
    "@action(reads=[\"temp_index\"], writes=[\"context_sections\"])\n",
    "def search_relevant_wiki_sections(state: State) -> State:\n",
    "    context_sections = list()\n",
    "    # magic to search the index\n",
    "\n",
    "    # Add citations to the information\n",
    "\n",
    "    return state.update(context_sections=context_sections)\n",
    "\n",
    "@action(reads=[\"context_sections\"], writes=[\"wikipedia_trend_report\"])\n",
    "def create_wikipedia_trend_report(state: State, topic: str, focus: str) -> State:\n",
    "    formatted_trend_prompt = trend_report_prompt.format(topic=topic, focus=focus,\n",
    "                                                        context_data=state['context_sections'])\n",
    "    wikipedia_trend_report = call_llm(formatted_trend_prompt)\n",
    "\n",
    "    return state.update(wikipedia_trend_report=wikipedia_trend_report)\n",
    "\n",
    "@action(reads=[\"wikipedia_trend_report\",\"trend_report\"], writes=[\"merged_trend_report\"])\n",
    "def merge_trend_reports(state: State, file_path: Path) -> State:\n",
    "    formatted_prompt = merge_trend_reports.format(trend_report = state['trend_report'],\n",
    "                                                  context_report = state['wikipedia_trend_report'])\n",
    "    merged_trend_report = call_llm(formatted_prompt)\n",
    "    return state.update(merged_trend_report=merged_trend_report)\n",
    "\n",
    "@action(reads=[\"wikipedia_trend_report\",\"report_data\"], writes=[\"executive_summary\"])\n",
    "def create_executive_summary(state: State, topic: str, focus: str) -> State:\n",
    "    formatted_executive_prompt = executive_summary_prompt.format(topic=topic, focus=focus,\n",
    "                                                         report=state['report_data']['report'],\n",
    "                                                         trend_report=state['merged_trend_report'])\n",
    "\n",
    "    executive_summary = call_llm(formatted_executive_prompt)\n",
    "    return state.update(executive_summary=executive_summary)"
   ],
   "id": "b8be796f1c4dfa7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "app = (\n",
    "    ApplicationBuilder()\n",
    "    .with_actions(\n",
    "        load_report_from_file,\n",
    "        create_trend_analysis,\n",
    "        create_search_follow_up_document,\n",
    "        search_wikipedia,\n",
    "        vectorize_and_index_wikipedia,\n",
    "        search_relevant_wiki_sections,\n",
    "        create_wikipedia_trend_report,\n",
    "        merge_trend_reports,\n",
    "        create_executive_summary\n",
    "    )\n",
    "    .with_transitions(\n",
    "        (\"load_report_from_file\", \"create_trend_analysis\"),\n",
    "        (\"create_trend_analysis\", \"create_search_follow_up_document\"),\n",
    "        (\"create_search_follow_up_document\", \"search_wikipedia\"),\n",
    "        (\"search_wikipedia\", \"vectorize_and_index_wikipedia\"),\n",
    "        (\"vectorize_and_index_wikipedia\", \"search_relevant_wiki_sections\"),\n",
    "        (\"search_relevant_wiki_sections\",\"create_wikipedia_trend_report\"),\n",
    "        (\"create_wikipedia_trend_report\", \"merge_trend_reports\"),\n",
    "        (\"merge_trend_reports\", \"create_executive_summary\"))\n",
    "    .with_entrypoint(\"load_report_from_file\")\n",
    "    .with_tracker(\n",
    "        \"local\",\n",
    "        project=f\"research_batch-single_run\",\n",
    "    )\n",
    "    .build()\n",
    ")"
   ],
   "id": "c505967de516b149",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "app.visualize(\"./graph\", format=\"png\")",
   "id": "51e2c1287109b097",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4e4e83b4e7c41310",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "formatted_trend_analysis_prompt = brief_analysis_prompt.format(topic=research_data['topic'],\n",
    "                                                               focus=research_data['focus'],\n",
    "                                                               report=research_data['report'],\n",
    "                                                               sources=research_data['formatted_report_grounding'])"
   ],
   "id": "36fa2e6f9af079d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trend_report = call_llm_flash(formatted_trend_analysis_prompt)",
   "id": "f94bfe1bb2b5bab5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "formatted_follow_up_prompt = follow_up_context_prompt.format(topic=research_data['topic'],\n",
    "                                                             focus=research_data['focus'],\n",
    "                                                             report=research_data['report'],\n",
    "                                                             trend_analysis=trend_report)"
   ],
   "id": "3400e683c70927d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "follow_up_context = call_llm_flash(formatted_follow_up_prompt)",
   "id": "b0db9ef9118f579f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "different_followups = re.findall(r'(##[\\s\\S]+?)(?=##|$)', follow_up_context, flags=re.DOTALL)\n",
    "follow_up_groups = dict()\n",
    "for group in different_followups:\n",
    "    group_name = group.split('\\n')[0]\n",
    "    followups = re.findall(r'[\\*-]\\s*(.+?)(?:\\n|$)', group, flags=re.DOTALL)\n",
    "    followups = [x.strip() for x in followups]\n",
    "    follow_up_groups[group_name.strip()] = followups"
   ],
   "id": "65c8c3db5dbbe266",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vectorized_sections = list()\n",
    "for context_search in tqdm(context_data):\n",
    "    context_topic = context_search['topic']\n",
    "    context_focus = context_search['focus']\n",
    "    context_query = context_search['query']\n",
    "    for wiki_page in tqdm(context_search['context']):\n",
    "        wiki_page_title = wiki_page['title']\n",
    "        for section_idx, section in tqdm(enumerate(wiki_page['sections'])):\n",
    "            section_copy = deepcopy(section)\n",
    "            section_copy['vector'] = encoder.encode(f\"{wiki_page_title}\\n{section_copy['title']}\\n{' '.join(section_copy['hierarchy_string'].split('|'))}\\n{section_copy['text']}\").tolist()\n",
    "\n",
    "            section_copy['topic'] = context_topic\n",
    "            section_copy['focus'] = context_focus\n",
    "            section_copy['query'] = context_query\n",
    "            section_copy['page_title'] = wiki_page_title\n",
    "            section_copy['section_idx'] = section_idx\n",
    "\n",
    "            vectorized_sections.append(section_copy)\n",
    "            torch.mps.empty_cache()\n"
   ],
   "id": "d349a0f1012c4fb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "context_index_data = pd.DataFrame(vectorized_sections)",
   "id": "20ff317e15149820",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "context_index_data",
   "id": "cf2d4725eff64d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "temp_research_table = index.create_table('temp_research', data=context_index_data, mode='overwrite')",
   "id": "fb0e28bfc941bbba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "temp_research_table.create_fts_index(['text','title'], replace=True)",
   "id": "ff2690e29c5f814f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "context_results = dict()\n",
    "all_context_documents = list()\n",
    "for group, followup_group in follow_up_groups.items():\n",
    "    all_search_results = list()\n",
    "    for follow_up in followup_group:\n",
    "        follow_up_vector = encoder.encode(follow_up).tolist()\n",
    "        torch.mps.empty_cache()\n",
    "\n",
    "        follow_up_search_vector = temp_research_table.search(follow_up_vector).distance_type('cosine').limit(20).to_pandas()\n",
    "        follow_up_search_fts = temp_research_table.search(follow_up).limit(20).to_pandas()\n",
    "        follow_up_search = pd.concat([follow_up_search_vector, follow_up_search_fts])\n",
    "        all_search_results.append(follow_up_search)\n",
    "    all_search_results = pd.concat(all_search_results)\n",
    "    all_search_results = all_search_results.drop_duplicates(subset=['page_title','section_idx'], keep='first')\n",
    "    all_search_results['section_start'] = all_search_results.groupby(['page_title','hierarchy_string'])['section_idx'].transform('min')\n",
    "    all_search_results = all_search_results.sort_values(by=['page_title','section_start','section_idx'])\n",
    "    context_results[group] = all_search_results\n",
    "    all_context_documents.append(all_search_results)\n",
    "\n",
    "\n",
    "all_context_documents = pd.concat(all_context_documents)\n",
    "all_context_documents = all_context_documents.drop_duplicates(subset=['page_title','section_idx'], keep='first')\n",
    "all_context_documents['section_start'] = all_context_documents.groupby(['page_title','hierarchy_string'])['section_idx'].transform('min')\n",
    "all_context_documents = all_context_documents.sort_values(by=['page_title','section_start','section_idx'])"
   ],
   "id": "22d3b8570a71ad2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_context_documents = all_context_documents.drop_duplicates(subset=['page_title','text'])\n",
    "all_context_documents = all_context_documents[all_context_documents['text'].str.strip() != '']"
   ],
   "id": "422a407bb0a84a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "51ddd768e899a53f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "formatted_context_sections = list()\n",
    "all_context_grounding = list()\n",
    "for _page_title, _group in all_context_documents.groupby(['page_title']):\n",
    "    # group_text = '\\n\\n'.join(_group['text'])\n",
    "    formatted_wiki_text = format_sections_w_citations(_group.to_dict(orient='records'), _page_title[0])\n",
    "    group_text = \"\"\n",
    "    for section in formatted_wiki_text:\n",
    "        formatted_context_sections.append(deepcopy(section))\n",
    "        _formatted_section = f\"\\n- {section['text']} ({section['citation']})\"\n",
    "        group_text += _formatted_section\n",
    "    group_text = group_text.strip()\n",
    "    all_context_grounding.append(f\"#### Title: {_page_title[0]}\\n\\n{group_text}\")\n",
    "\n",
    "context_grounding = '\\n\\n'.join(all_context_grounding).strip()\n",
    "print(len(context_grounding.split(' ')))\n",
    "# all_context_grounding.append(context_grounding)"
   ],
   "id": "6437e66d5e996089",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "areas_of_interest = list()\n",
    "for follow_up_type, follow_up_points in follow_up_groups.items():\n",
    "    points_to_follow_up = ['- ' + x for x in follow_up_points]\n",
    "    points_to_follow_up = '\\n'.join(points_to_follow_up)\n",
    "    areas_of_interest.append(points_to_follow_up)"
   ],
   "id": "f48c583ea3f4688c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "formatted_prompts = list()\n",
    "formatted_extraction_prompt = extract_context_information_prompt.format(topic=context_topic,\n",
    "                                                                            focus=context_focus,\n",
    "                                                                            areas_of_interest=_area_of_interest,\n",
    "                                                                            trend_analysis=trend_report,\n",
    "                                                                            articles=context_grounding)\n",
    "formatted_prompts.append(formatted_extraction_prompt)"
   ],
   "id": "5de87b21ffd47cad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "follow_up_extractions = list()\n",
    "for _follow_up_prompt in tqdm(formatted_prompts):\n",
    "    extraction = call_llm_flash(_follow_up_prompt, max_tokens=7500)\n",
    "    follow_up_extractions.append(extraction)"
   ],
   "id": "c7c506ea0bfca580",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_follow_up_extractions = '\\n\\n----------\\n\\n'.join(follow_up_extractions)",
   "id": "f7d426cabc63a28f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "formatted_trend_interpolation_prompt = trend_interpolation_prompt.format(topic=context_topic,\n",
    "                                                                         focus=context_focus,\n",
    "                                                                         trend_analysis=trend_report,\n",
    "                                                                         notes=all_follow_up_extractions)\n",
    "len(formatted_extraction_prompt.split(' '))"
   ],
   "id": "cc0ce91c0cfe3ddc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "expanded_trend_report = call_llm_flash(formatted_trend_interpolation_prompt, max_tokens=10000)",
   "id": "4303afc1501c9a2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "merged_trend_formatted_prompt = merged_trend_report_prompt.format(topic=context_topic,\n",
    "                                                                  focus=context_focus,\n",
    "                                                                  initial_report=trend_report,\n",
    "                                                                  additional_report=expanded_trend_report)"
   ],
   "id": "c8ecac0f4e9f2f5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "merged_trend_report = call_llm_flash(merged_trend_formatted_prompt, max_tokens=10000)",
   "id": "351941c7dc68dc39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "99bafe1fe53e750d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "full_research_folder = Path('wonky_data/data/full_research')\n",
    "full_research_folder = full_research_folder.joinpath(research[0].stem)\n",
    "full_research_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "full_research_documents_folder = full_research_folder.joinpath('documents')\n",
    "full_research_documents_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "full_research_trace_folder = full_research_folder.joinpath('trace')\n",
    "full_research_trace_folder.mkdir(parents=True, exist_ok=True)"
   ],
   "id": "db966fcb2b50098d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "report_file_name",
   "id": "95322e6873e3ba34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "context_grounding_save_out = dict()\n",
    "for _area_of_interest, _context in context_results.items():\n",
    "    _cleaned_context = _context.copy()\n",
    "    _cleaned_context['vector'] = _cleaned_context['vector'].apply(lambda x: x.tolist())\n",
    "    context_grounding_save_out[_area_of_interest] = _cleaned_context.to_dict(orient='records')"
   ],
   "id": "77ded10f454238ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "formatted_executive_summary_prompt = executive_summary_prompt.format(topic=research_data['topic'],\n",
    "                                                                     focus=research_data['focus'],\n",
    "                                                                     trend_report=merged_trend_report,\n",
    "                                                                     report=research_data['report'])"
   ],
   "id": "496ec50e5f9c8abd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "executive_summary = call_llm_flash(formatted_executive_summary_prompt, max_tokens=10000)",
   "id": "1d6d48f19b7ab3d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trace_data = {\"trend_report\":trend_report,\n",
    "                     \"report\":research_data['report'],\n",
    "                     \"follow_up_context\":follow_up_context,\n",
    "                     \"expanded_trend_report\":expanded_trend_report,\n",
    "                     \"trend_research\":context_grounding_save_out,\n",
    "                     \"topic\":research_data['topic'],\n",
    "                     \"focus\":research_data['focus'],\n",
    "                     \"source_file_name\":report_file_name,\n",
    "                     \"executive_summary\":executive_summary,\n",
    "              \"followup_extractions\":all_follow_up_extractions,\n",
    "              \"merged_trend_report\":merged_trend_report}\n",
    "\n",
    "documents_to_save = {\"trend_report\":trend_report,\n",
    "                     \"report\":research_data['report'],\n",
    "                     \"follow_up_context\":follow_up_context,\n",
    "                     \"expanded_trend_report\":expanded_trend_report,\n",
    "                     \"source_file_name\":report_file_name,\n",
    "                     \"executive_summary\":executive_summary,\n",
    "                     \"followup_extractions\":all_follow_up_extractions,\n",
    "                     \"merged_trend_report\":merged_trend_report}"
   ],
   "id": "da32c25b0799c3fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(full_research_trace_folder.joinpath('research_data.json'),'w') as f:\n",
    "    json.dump(trace_data,f)"
   ],
   "id": "d52cff4ce282c3fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for document_type, document in documents_to_save.items():\n",
    "    with open(full_research_documents_folder.joinpath(document_type+'.md'),'w') as f:\n",
    "        f.write(document)"
   ],
   "id": "6a220e4bcff994e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"topic: {trace_data['topic']} with a focus on: {trace_data['focus']}\")",
   "id": "561c2d0dd41a791e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "41cbd2cc3efa08b1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
