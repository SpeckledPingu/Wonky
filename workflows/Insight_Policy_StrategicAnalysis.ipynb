{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import lancedb\n",
    "from openai import OpenAI\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from fuzzy_json import loads as fuzzy_loads\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "load_dotenv('env_var')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "from copy import deepcopy\n",
    "\n",
    "from text_lookup import get_text_by_chunk_id, get_chunk_text_by_indexes_expansion, get_text_by_indexes_expansion, CitationFormatter, make_on_the_fly_citations,get_text_by_indexes_sections\n",
    "\n",
    "project_folder = Path('project_research')\n",
    "project_folder.mkdir(parents=True, exist_ok=True)\n",
    "research_json_folder = project_folder.joinpath('json_data')\n",
    "research_json_folder.mkdir(parents=True, exist_ok=True)\n",
    "database_location = project_folder.joinpath('research.sqlite')\n",
    "\n",
    "document_database = Path('../wonky_data/databases/documents.sqlite')\n",
    "document_conn = sqlite3.connect(document_database)\n",
    "\n",
    "conn = sqlite3.connect(database_location)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "with open('insight_prompts.json','r') as f:\n",
    "    prompts = json.load(f)"
   ],
   "id": "7441465f241d1c92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "index = lancedb.connect('../wonky_data/crs_reports/')\n",
    "table = index.open_table('sections')\n",
    "encoder = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', device='mps',trust_remote_code=True)"
   ],
   "id": "9ca7d02a6be9743f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "def _parse_single_policy_to_markdown(policy: dict, index: int) -> str:\n",
    "    \"\"\"\n",
    "    Parses a single policy dictionary and converts it into a Markdown string.\n",
    "\n",
    "    Args:\n",
    "        policy: A Python dictionary for a single policy.\n",
    "        index: The policy number for titling (e.g., 1, 2, 3).\n",
    "\n",
    "    Returns:\n",
    "        A string containing the formatted Markdown for a single policy.\n",
    "    \"\"\"\n",
    "    policy_lines = []\n",
    "\n",
    "    policy_lines.append(\"---\")\n",
    "    policy_type = policy.get('policyType', 'N/A')\n",
    "    policy_lines.append(f\"## Policy {policy.get('policyName', 'Unnamed Policy')} (`{policy_type}`)\")\n",
    "\n",
    "    # Policy Details\n",
    "    policy_lines.append(\"\\n### Policy Details\")\n",
    "    policy_lines.append(f\"**Primary Objective:** {policy.get('primaryObjective', 'N/A')}\")\n",
    "    policy_lines.append(f\"**Mechanism of Action:** {policy.get('mechanismOfAction', 'N/A')}\")\n",
    "    policy_lines.append(f\"\\n**Summary:**\\n{policy.get('policyDetails', 'No details provided.')}\")\n",
    "\n",
    "    # Stakeholders\n",
    "    stakeholders = policy.get('keyStakeholders', {})\n",
    "    if stakeholders:\n",
    "        policy_lines.append(\"\\n#### Key Stakeholders\")\n",
    "        policy_lines.append(f\"- **Beneficiaries:** {stakeholders.get('beneficiaries', 'N/A')}\")\n",
    "        policy_lines.append(f\"- **Regulated Parties:** {stakeholders.get('regulatedParties', 'N/A')}\")\n",
    "        policy_lines.append(f\"- **Implementing Agency:** {stakeholders.get('implementingAgency', 'N/A')}\")\n",
    "\n",
    "    # Arguments\n",
    "    policy_lines.append(\"\\n### Analysis & Arguments\")\n",
    "\n",
    "    arguments_in_favor = policy.get('argumentsInFavor', [])\n",
    "    policy_lines.append(\"\\n**Arguments In Favor:**\")\n",
    "    if arguments_in_favor:\n",
    "        for arg in arguments_in_favor:\n",
    "            policy_lines.append(f\"- {arg}\")\n",
    "    else:\n",
    "        policy_lines.append(\"- None mentioned.\")\n",
    "\n",
    "    arguments_against = policy.get('argumentsAgainst', [])\n",
    "    policy_lines.append(\"\\n**Arguments Against / Challenges:**\")\n",
    "    if arguments_against:\n",
    "        for arg in arguments_against:\n",
    "            policy_lines.append(f\"- {arg}\")\n",
    "    else:\n",
    "        policy_lines.append(\"- None mentioned.\")\n",
    "\n",
    "    policy_lines.append(f\"\\n**Author's Apparent Stance:** {policy.get('authorsApparentStance', 'N/A')}\")\n",
    "\n",
    "    # Evidence and Sources\n",
    "    policy_lines.append(\"\\n### Evidence & Sources\")\n",
    "    policy_lines.append(\"\\n> **Specific Evidence:**\")\n",
    "    policy_lines.append(f\"> {policy.get('specificEvidence', 'No specific evidence quoted.')}\")\n",
    "\n",
    "    source_locations = policy.get('sourceLocations', [])\n",
    "    policy_lines.append(\"\\n**Source Locations:**\")\n",
    "    if isinstance(source_locations, list):\n",
    "        for loc in source_locations:\n",
    "            policy_lines.append(f\"- `{loc}`\")\n",
    "    elif isinstance(source_locations, str):\n",
    "        policy_lines.append(f\"- `{source_locations}`\")\n",
    "    else:\n",
    "        policy_lines.append(\"- None mentioned.\")\n",
    "\n",
    "    policy_lines.append(\"\\n\")\n",
    "\n",
    "    return \"\\n\".join(policy_lines)\n",
    "\n",
    "def parse_crs_json_to_markdown(data: dict) -> str:\n",
    "    \"\"\"\n",
    "    Parses a dictionary (from CRS JSON) and converts it into a readable Markdown document.\n",
    "\n",
    "    Args:\n",
    "        data: A Python dictionary conforming to the CRS analysis JSON schema.\n",
    "\n",
    "    Returns:\n",
    "        A string containing the formatted Markdown document.\n",
    "    \"\"\"\n",
    "    markdown_lines = []\n",
    "\n",
    "    # --- Part 1: Report Information ---\n",
    "    report_info = data.get(\"reportInfo\", {})\n",
    "    if report_info:\n",
    "        markdown_lines.append(f\"# {report_info.get('reportTitle', 'Untitled Report')}\")\n",
    "        markdown_lines.append(\"---\")\n",
    "        markdown_lines.append(f\"**Report Number:** {report_info.get('reportNumber', 'N/A')}\")\n",
    "        markdown_lines.append(f\"**Publication Date:** {report_info.get('publicationDate', 'N/A')}\")\n",
    "        analysts = \", \".join(report_info.get('crsAnalysts', ['N/A']))\n",
    "        markdown_lines.append(f\"**Analysts:** {analysts}\")\n",
    "        markdown_lines.append(\"\\n> ### Overall Subject\")\n",
    "        markdown_lines.append(f\"> {report_info.get('overallSubject', 'No summary provided.')}\\n\")\n",
    "\n",
    "    # --- Part 2: Policies ---\n",
    "    policies = data.get(\"policies\", [])\n",
    "    if not policies:\n",
    "        markdown_lines.append(\"## No policies were identified in this report.\")\n",
    "        return \"\\n\".join(markdown_lines)\n",
    "\n",
    "    for i, policy in enumerate(policies, 1):\n",
    "        policy_markdown = _parse_single_policy_to_markdown(policy, i)\n",
    "        markdown_lines.append(policy_markdown)\n",
    "\n",
    "    return \"\\n\".join(markdown_lines)"
   ],
   "id": "4713f2de7a2b1036",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def format_evidence(evidence_list):\n",
    "    \"\"\"Formats the evidence list into a Markdown string.\"\"\"\n",
    "    markdown = \"\"\n",
    "    if not evidence_list or not isinstance(evidence_list, list):\n",
    "        return \"No evidence provided.\\n\"\n",
    "\n",
    "    for i, item in enumerate(evidence_list):\n",
    "        markdown += f\"  - **{item.get('Description', 'N/A')}**\\n\"\n",
    "        markdown += f\"    - **Key Data/Details:** {item.get('Key Data/Details', 'N/A')}\\n\"\n",
    "        markdown += f\"    - **Methodology Note:** {item.get('Methodology Note', 'N/A')}\\n\"\n",
    "        markdown += f\"    - **Source Note:** {item.get('Source Note', 'N/A')}\\n\"\n",
    "    return markdown\n",
    "\n",
    "\n",
    "def format_list(items, title):\n",
    "    \"\"\"Formats a simple list of strings into a Markdown list.\"\"\"\n",
    "    markdown = f\"#### *{title}*\\n\"\n",
    "    if not items or not isinstance(items, list):\n",
    "        return markdown + \"- N/A\\n\"\n",
    "    for item in items:\n",
    "        markdown += f\"- {item}\\n\"\n",
    "    return markdown\n",
    "\n",
    "\n",
    "def format_evidence(evidence_list):\n",
    "    \"\"\"Formats the evidence list into a Markdown string using the new schema.\"\"\"\n",
    "    markdown = \"\"\n",
    "    if not evidence_list or not isinstance(evidence_list, list):\n",
    "        return \"No evidence provided.\\n\"\n",
    "\n",
    "    for i, item in enumerate(evidence_list):\n",
    "        # Using new camelCase keys from the updated schema\n",
    "        markdown += f\"  - **{item.get('description', 'N/A')}**\\n\"\n",
    "        markdown += f\"    - **Details:** {item.get('details', 'N/A')}\\n\"\n",
    "        markdown += f\"    - **Methodology:** {item.get('methodology', 'N/A')}\\n\"\n",
    "        markdown += f\"    - **Source:** {item.get('source', 'N/A')}\\n\"\n",
    "    return markdown\n",
    "\n",
    "\n",
    "def format_list(items, title):\n",
    "    \"\"\"Formats a simple list of strings into a Markdown list.\"\"\"\n",
    "    markdown = f\"#### {title}\\n\"\n",
    "    if not items or not isinstance(items, list):\n",
    "        return markdown + \"- N/A\\n\"\n",
    "    for item in items:\n",
    "        markdown += f\"- {item}\\n\"\n",
    "    return markdown\n",
    "\n",
    "\n",
    "def generate_markdown(data):\n",
    "    if not isinstance(data, list):\n",
    "        return \"Error: JSON data must be a list of insight objects.\"\n",
    "\n",
    "    full_markdown = \"\"\n",
    "    for i, insight in enumerate(data):\n",
    "        # --- Main Title for the Insight (using 'statement') ---\n",
    "        full_markdown += f\"## Insight: \\n\\n### *{insight.get('statement', 'No Title Provided')}*\\n\\n\"\n",
    "\n",
    "        # --- Source Information (using new keys) ---\n",
    "        full_markdown += \"## 1. Source Information\\n\"\n",
    "        full_markdown += f\"- **Title:** {insight.get('sourceTitle', 'N/A')}\\n\"\n",
    "        full_markdown += f\"- **Author:** {insight.get('author', 'N/A')}\\n\"\n",
    "        # Joining list of locations for cleaner output\n",
    "        locations = insight.get('location', ['N/A'])\n",
    "        full_markdown += f\"- **Location:** {', '.join(locations)}\\n\\n\"\n",
    "\n",
    "        # --- Comprehensive Explanation (using 'explanation') ---\n",
    "        full_markdown += \"## 2. Comprehensive Explanation\\n\"\n",
    "        full_markdown += f\"{insight.get('explanation', 'N/A')}\\n\\n\"\n",
    "\n",
    "        # --- Evidence Section (using new keys) ---\n",
    "        full_markdown += \"## 3. Evidence & Reasoning\\n\\n\"\n",
    "        full_markdown += \"### Evidence For\\n\"\n",
    "        full_markdown += format_evidence(insight.get('evidenceFor'))\n",
    "        full_markdown += \"\\n\"\n",
    "\n",
    "        full_markdown += \"### Reasoning For\\n\"\n",
    "        full_markdown += insight.get('reasoningFor', 'N/A') + '\\n\\n'\n",
    "\n",
    "        full_markdown += \"### Evidence Against\\n\"\n",
    "        full_markdown += f\"{insight.get('evidenceAgainst', 'N/A')}\\n\\n\"\n",
    "\n",
    "        full_markdown += \"### Reasoning Against\\n\"\n",
    "        full_markdown += insight.get('reasoningAgainst', 'N/A') + \"\\n\\n\"\n",
    "\n",
    "        full_markdown += \"### Author's Position\\n\"\n",
    "        full_markdown += insight.get('position', 'N/A') + \"\\n\\n\"\n",
    "\n",
    "        # --- Strength of Insight (using 'strength' and its sub-keys) ---\n",
    "        strength = insight.get('strength', {})\n",
    "        full_markdown += \"## 4. Strength of Insight\\n\"\n",
    "        full_markdown += f\"- **Assessment:** {strength.get('assessment', 'N/A')}\\n\"\n",
    "        full_markdown += f\"- **Confidence:** {strength.get('confidence', 'N/A')}\\n\"\n",
    "        full_markdown += f\"- **Plausibility:** {strength.get('plausibility', 'N/A')}\\n\\n\"\n",
    "\n",
    "        # --- Actionable Recommendations (using 'implications' and its sub-keys) ---\n",
    "        recommendations = insight.get('implications', {})\n",
    "        full_markdown += \"## 5. Actionable Implications\\n\"\n",
    "        full_markdown += f\"- **If True:** {recommendations.get('ifTrue', 'N/A')}\\n\"\n",
    "        full_markdown += f\"- **Potential Use:** {recommendations.get('use', 'N/A')}\\n\"\n",
    "        full_markdown += f\"- **If False:** {recommendations.get('ifFalse', 'N/A')}\\n\\n\"\n",
    "\n",
    "        # --- Indexing (using 'indexing' and its sub-keys) ---\n",
    "        # indexing = insight.get('indexing', {})\n",
    "        # full_markdown += \"## 6. Indexing\\n\"\n",
    "        # full_markdown += format_list(indexing.get('generalTopics', []), \"General Topics\")\n",
    "        # full_markdown += format_list(indexing.get('specificTopics', []), \"Specific Topics\")\n",
    "        # full_markdown += format_list(indexing.get('generalKeywords', []), \"General Keywords\")\n",
    "        # full_markdown += format_list(indexing.get('specificKeywords', []), \"Specific Keywords\")\n",
    "        # full_markdown += \"\\n\"\n",
    "\n",
    "        # --- Unanswered Questions (using 'questions') ---\n",
    "        full_markdown += \"## 6. Unanswered Questions\\n\"\n",
    "        full_markdown += format_list(insight.get('questions', []), \"\")\n",
    "\n",
    "\n",
    "        # --- Separator for next insight ---\n",
    "        if i < len(data) - 1:\n",
    "            full_markdown += \"\\n---\\n\\n\"\n",
    "\n",
    "    return full_markdown\n"
   ],
   "id": "9e8c65cf431fc4b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "def call_llm(query, temperature=0.35, seed=42, model=\"gemma-3-12b-it-qat\"):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        seed=seed,\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "model = \"gemini-2.0-flash\"\n",
    "total_tokens = list()\n",
    "\n",
    "def call_llm_flash(query, temperature=0.1, seed=42, max_tokens=8193 ):\n",
    "    client = genai.Client(api_key=os.environ['GEMINI_API_KEY'])\n",
    "    retries = 3\n",
    "    time_delay = 15\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=model,\n",
    "                contents=[query],\n",
    "                config=types.GenerateContentConfig(\n",
    "                    max_output_tokens=max_tokens,\n",
    "                    temperature=temperature,\n",
    "                    seed=seed\n",
    "                )\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"Retries left: {retries - i}\")\n",
    "            time.sleep(time_delay)\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "    total_tokens.append({'prompt_tokens':response.usage_metadata.prompt_token_count,\n",
    "                         'completion_tokens':response.usage_metadata.candidates_token_count,\n",
    "                         'total_tokens':response.usage_metadata.total_token_count,\n",
    "                         'timestamp':datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")})\n",
    "\n",
    "    return response.text"
   ],
   "id": "e741d92533bb1d06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def format_enriched_report(extracted_article, full_document_df, report_sections, overview_type):\n",
    "    article_pages = extracted_article.split('---')\n",
    "    article_metadata = full_document_df.iloc[0].to_dict()\n",
    "\n",
    "    article_metadata['overview'] = extracted_article\n",
    "    article_metadata['overview_type'] = overview_type\n",
    "    article_metadata['overview_pages'] = article_pages\n",
    "\n",
    "    used_citations = list()\n",
    "    for section in report_sections:\n",
    "        _citation = section['citation']\n",
    "        if _citation in extracted_article:\n",
    "            used_citations.append(section)\n",
    "\n",
    "    article_metadata['overview_citations'] = sorted([x['citation'] for x in used_citations])\n",
    "    article_metadata['overview_cite_sources'] = used_citations\n",
    "    return article_metadata"
   ],
   "id": "7a2c6d8477c803c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def xml_passage_text(_article, _article_meta):\n",
    "    passage_text = CitationFormatter().formatter_xml_tag_article(_article['content'].to_list(),\n",
    "                                                        _article['citation'].to_list()\n",
    "                                                        )\n",
    "    passage_text = f\"\"\"# Title: {_article_meta['title']}\n",
    "    # Report ID: {_article_meta['id']}\n",
    "\n",
    "    {passage_text}\"\"\"\n",
    "    return passage_text"
   ],
   "id": "ac4400e4936b7159",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"Agricultural subsidies on rural economics.\"\n",
    "query_vec = encoder.encode(query)\n",
    "search_results = table.search(query_vec).limit(5).to_pandas()\n",
    "article_title_list = search_results[['title','id']].to_dict(orient='records')"
   ],
   "id": "8644490ab69df38a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PolicyDocument():\n",
    "    def __init__(self, search_result, search_position):\n",
    "        self.search_position = search_position\n",
    "        self.search_result = search_result\n",
    "        self.chunks = list()\n",
    "        self.passages = list()\n",
    "        self.chunk_text = list()\n",
    "        self.passage_text = list()\n",
    "        self.insights = list()\n",
    "        self.policies = list()\n",
    "        self.citation_mapping = list()\n",
    "        self.variables = dict()"
   ],
   "id": "85490bf4a397294a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Get the text with the paragraph level citations\n",
    "policy_documents = list()\n",
    "for index, row in search_results.iterrows():\n",
    "    _passages = get_text_by_indexes_sections(row['id'],\n",
    "                                                       start_index=row['start_index'],\n",
    "                                                       end_index=row['end_index'],\n",
    "                                                       conn=document_conn)\n",
    "    _passage_text = xml_passage_text(_passages, row)\n",
    "    policy_document = PolicyDocument(row, index)\n",
    "    policy_document.passages = _passages\n",
    "    policy_document.passage_text = _passage_text\n",
    "    policy_document.variables['insight_extraction_prompt'] = prompts['insight_extraction'].format(document=_passage_text)\n",
    "\n",
    "    citation_mapping = {citation:chunk for citation, chunk in zip(_passages['citation'].values, _passages['chunk_id'].values)}\n",
    "    policy_document.citation_mapping = citation_mapping\n",
    "\n",
    "    policy_documents.append(policy_document)"
   ],
   "id": "86b047a55cb0a9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Identify the locations of the different citations",
   "id": "b41fb6ee36024705"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for policy_document in tqdm(policy_documents):\n",
    "    insights = call_llm_flash(policy_document.variables['insight_extraction_prompt'], temperature=0.1)\n",
    "    insights_citations = re.findall(r'\\*\\*\\d+\\. Insight:\\*\\* (.*?)\\n\\* \\*\\*Location in Document:\\*\\*(.+?)(?:\\n\\n|$)',\n",
    "                                    insights,\n",
    "                                    flags=re.MULTILINE|re.DOTALL)\n",
    "    insight_mapping = list()\n",
    "    for _insight in insights_citations:\n",
    "        insight_mapping.append({'insight': _insight[0], 'location':re.findall(r'\\[(.*?)\\]', _insight[1])})\n",
    "    policy_document.insights = insight_mapping"
   ],
   "id": "2f5c90f5f6ab7a85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch_size = 4\n",
    "\n",
    "for policy_document in policy_documents:\n",
    "    insight_batches = list()\n",
    "    _insights = policy_document.insights\n",
    "    if len(_insights) <= batch_size:\n",
    "        all_insights = '\\n'.join(['* ' + x['insight'] for x in _insights[:batch_size+1]])\n",
    "        insight_batches.append(all_insights)\n",
    "\n",
    "    if len(_insights) > batch_size:\n",
    "        for i in range(len(_insights) // batch_size + 1):\n",
    "            all_insights = '\\n'.join(['* ' + x['insight'] for x in _insights[i*batch_size:(i+1)*batch_size]])\n",
    "            insight_batches.append(all_insights)\n",
    "\n",
    "    article_insights = list()\n",
    "    for _insight_batch in tqdm(insight_batches):\n",
    "        batch_insight_prompt = prompts['insight_template_instructions_all_insights'].format(insights=_insight_batch,\n",
    "                                                                           document=policy_document.passage_text)\n",
    "        print(len(batch_insight_prompt.split(' ')), len(prompts['insight_template_instructions_all_insights'].split(' ')))\n",
    "        batch_insight_report = call_llm_flash(batch_insight_prompt, temperature=0.1)\n",
    "        article_insights.append(batch_insight_report)\n",
    "    policy_document.variables['raw_insight_text'] = article_insights"
   ],
   "id": "1ca56fd68cef7327",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for policy_document in policy_documents:\n",
    "    _insights = list()\n",
    "    for _batch in policy_document.variables['raw_insight_text']:\n",
    "        try:\n",
    "            _insights.extend(fuzzy_loads(re.search(r'```json(.+?)```', _batch, flags=re.DOTALL).group(1)))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "    policy_document.insights = pd.DataFrame(_insights)"
   ],
   "id": "a2d7f8db139adeeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "policy_document.insights",
   "id": "6fbf93ac62ad980",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def chunk_mapper(citations, _mapping):\n",
    "    mapped_citations = [_mapping.get(_cite.strip('<[]()>/\\\\'), None) for _cite in citations]\n",
    "    mapped_citations = list(set(mapped_citations))\n",
    "    return mapped_citations\n",
    "\n",
    "for policy_document in tqdm(policy_documents):\n",
    "    policy_document.insights['mapped_chunks'] = policy_document.insights['location'].apply(lambda x: chunk_mapper(x, policy_document.citation_mapping))\n",
    "    policy_document.insights = policy_document.insights.explode('mapped_chunks')"
   ],
   "id": "7327eaa171d15797",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Policy Extraction Prompt",
   "id": "3d64f087b06bd6f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "policy_extraction_prompt = \"\"\"\n",
    "Your goal is to identify all distinct policies discussed in the provided text and format the output as a single, clean JSON object according to the rules and schema below.\n",
    "\n",
    "**Rules for Extraction:**\n",
    "\n",
    "1.  **Analyze Full Text:** Read the entire report text provided at the end of this prompt.\n",
    "2.  **Extract Report Info:** Identify the report's general information (title, number, date, authors, overall subject) and populate the `reportInfo` object.\n",
    "3.  **Identify All Policies:** Scan the report to identify every distinct policy. A policy can be an existing law, a proposed bill, or a \"policy option\" presented by the author. Create a JSON object for each one in the `policies` list.\n",
    "4.  **Populate Policy Fields with High Detail:** For each policy, adhere to the following field-specific rules:\n",
    "    * **`primaryObjective`**: Extract the specific, stated goal of the policy. What problem is it explicitly designed to solve? Look for phrases like \"in order to,\" \"the purpose of this is,\" or \"this policy aims to address.\"\n",
    "    * **`mechanismOfAction`**: Describe the concrete, functional steps of how the policy works. Do not describe the goal, but the *actions*. For example: \"It authorizes $50M in block grants to states,\" \"It imposes a 2% tariff on imported steel,\" or \"It directs the EPA to develop new emissions standards.\"\n",
    "    * **`policyDetails`**: Provide a comprehensive, detailed summary of the policy. This field should synthesize the objective, mechanism, history, and any other key details mentioned in the report into a thorough paragraph. This should be the most detailed field for the policy.\n",
    "    * **`argumentsInFavor`**: Identify every distinct argument *for* the policy mentioned in the text. Each unique argument should be a separate string in this list.\n",
    "    * **`argumentsAgainst`**: Identify every distinct argument, challenge, or drawback *against* the policy mentioned in the text. Each unique point should be a separate string in this list.\n",
    "    * **`authorsApparentStance`**: Infer the author's overall leaning on this specific policy based on framing, tone, and the balance of arguments.\n",
    "    * **`specificEvidence`**: Provide direct quotes or specific data points (e.g., statistics, figures) from the report that serve as the primary evidence for your analysis of this policy.\n",
    "5.  **Return Clean JSON:** Your final output must be **only the JSON object**, with no introductory text, explanations, or markdown formatting.\n",
    "\n",
    "**JSON Schema for Output:**\n",
    "\n",
    "```json\n",
    "{{\n",
    "  \"reportInfo\": {{\n",
    "    \"reportNumber\": \"string (e.g., R40123)\",\n",
    "    \"overallSubject\": \"string (A 1-2 sentence summary of the report's main issue)\"\n",
    "  }},\n",
    "  \"policies\": [\n",
    "    {{\n",
    "      \"policyName\": \"string (Official name, bill number, or descriptive name)\",\n",
    "      \"policyType\": \"string (Enum: 'Existing Law / Regulation', 'Proposed Legislation (Bill)', 'Policy Option / Alternative', 'Executive Action', 'Other')\",\n",
    "      \"primaryObjective\": \"string (The specific, stated goal of the policy)\",\n",
    "      \"mechanismOfAction\": \"string (The concrete, functional steps of how the policy works)\",\n",
    "      \"policyDetails\": \"string (A comprehensive, detailed summary of the policy)\",\n",
    "      \"keyStakeholders\": {{\n",
    "        \"beneficiaries\": \"string (Who stands to benefit?)\",\n",
    "        \"regulatedParties\": \"string (Who must comply or is most impacted?)\",\n",
    "        \"implementingAgency\": \"string (Which government agency is in charge?)\"\n",
    "      }},\n",
    "      \"argumentsInFavor\": [\"string (List of distinct arguments for the policy)\"],\n",
    "      \"argumentsAgainst\": [\"string (List of distinct arguments/challenges against the policy)\"],\n",
    "      \"authorsApparentStance\": \"string (Enum: 'Generally Favorable', 'Generally Unfavorable', 'Strictly Neutral / Indiscernible')\",\n",
    "      \"sourceLocations\": [\"string (A specific citation from the report, e.g., R40123_ref123)\"],\n",
    "      \"specificEvidence\": \"string (Direct quotes or specific data points from the report that serve as evidence for the analysis)\"\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "```\n",
    "\n",
    "{document_text}\n",
    "\"\"\""
   ],
   "id": "b9d80b7dcc6ea90c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for policy_document in policy_documents:\n",
    "    chunk_text = list()\n",
    "    for _chunk_id in policy_document.insights['mapped_chunks'].unique():\n",
    "        chunk_text.append(get_text_by_chunk_id(_chunk_id, document_conn))\n",
    "    chunk_text = pd.concat(chunk_text)\n",
    "    policy_document.variables['insight_chunks'] = chunk_text\n",
    "    policy_text = CitationFormatter().formatter_xml_tag_article(chunk_text['passage_text'].to_list(),\n",
    "                                                    chunk_text['chunk_id'].to_list()\n",
    "                                                    )\n",
    "    policy_text = f\"\"\"# Title: {chunk_text.iloc[0]['title']}\n",
    "    # Report ID: {chunk_text.iloc[0]['id']}\n",
    "\n",
    "    {policy_text}\"\"\"\n",
    "    policy_document.variables['formatted_insight_chunks'] = policy_text\n",
    "    policy_document.variables['policy_extraction_prompt'] = policy_extraction_prompt.format(document_text=policy_text)"
   ],
   "id": "37c443f3d8b4e4e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "extracted_policies = list()\n",
    "for policy_document in tqdm(policy_documents):\n",
    "    _extracted_policies = call_llm_flash(policy_document.variables['policy_extraction_prompt'], temperature=0.1, max_tokens=10000)\n",
    "    extracted_policies_json = fuzzy_loads(re.search(r'```json(.+?)```', _extracted_policies, flags=re.DOTALL).group(1).strip())\n",
    "    policy_document.policies = pd.DataFrame(extracted_policies_json['policies'])\n",
    "    policy_document.policies = policy_document.policies.explode('sourceLocations')\n",
    "    policy_document.policies['report_number'] = extracted_policies_json['reportInfo']['reportNumber']\n",
    "    policy_document.policies['overallSubject'] = extracted_policies_json['reportInfo']['overallSubject']"
   ],
   "id": "cd4f73c205abf2ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "policy_document.__dict__.keys()",
   "id": "590a0cea08f6e025",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "insights_related_to_policy",
   "id": "f42972750f78f011",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "_policies",
   "id": "989313210e63d8d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for policy_document in tqdm(policy_documents):\n",
    "    _insights = policy_document.insights\n",
    "    _policies = policy_document.policies\n",
    "    policy_insight_sources = list()\n",
    "    for index, row in _policies.iterrows():\n",
    "        policy_card = _parse_single_policy_to_markdown(row.to_dict(), index=0).strip()\n",
    "\n",
    "        insights_related_to_policy = _insights[_insights['mapped_chunks'] == row['sourceLocations']]\n",
    "        insight_card = generate_markdown(insights_related_to_policy.to_dict(orient='records'))\n",
    "\n",
    "        source_cards = list()\n",
    "        for chunk_id in insights_related_to_policy['mapped_chunks'].unique():\n",
    "            _chunk_text = get_text_by_chunk_id(chunk_id, document_conn)\n",
    "            report_id = _chunk_text.iloc[0]['id']\n",
    "            source_card_text = get_text_by_indexes_sections(report_id,\n",
    "                                                        int(_chunk_text['start_index'].min()),\n",
    "                                                        int(_chunk_text['end_index'].max()),\n",
    "                                                        document_conn)\n",
    "            source_card_text = CitationFormatter().formatter_xml_tag_article(source_card_text['content'].to_list(),\n",
    "                                                    source_card_text['citation'].to_list()\n",
    "                                                    )\n",
    "            source_cards.append(source_card_text)\n",
    "        policy_insight_sources.append({\n",
    "            'policy_card': policy_card,\n",
    "            'insight_card': insight_card,\n",
    "            'source_cards': '\\n-----\\n'.join(source_cards),\n",
    "            'policy':row.to_dict()\n",
    "        })\n",
    "    print(len(policy_insight_sources))\n",
    "    policy_document.variables['policy_insight_sources'] = policy_insight_sources"
   ],
   "id": "bc799da36927c582",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "strategic_analysis_guide_template = \"\"\"Only respond with the sections identifed in the phases. Do not write tables, do not introduce your response, do not conclude your response.\n",
    "\n",
    "**1. Source Materials**\n",
    "\n",
    "This analysis is to be performed using only the following embedded source materials.\n",
    "\n",
    "### **Provided Policy Card**\n",
    "{policy_card_text}\n",
    "\n",
    "### **Provided Insight Cards**\n",
    "{insight_cards_text}\n",
    "\n",
    "### **Source Documents**\n",
    "{source_card_text}\n",
    "\n",
    "**2. Core Task & Output**\n",
    "\n",
    "* **Task:** Using the provided Policy Card and Insight Cards, analyze the policy's long-term resilience and effectiveness under conditions of high uncertainty. This involves identifying key external driving forces, developing a set of plausible future scenarios, and formulating robust strategies that can succeed across multiple potential futures.\n",
    "* **Guiding Principle on Limited Information:** This analysis must be based *only* on the provided source materials. If information is insufficient to complete a section, you must explicitly state the limitation in that section and detail the gap in Phase 5. Do not make assumptions or use outside knowledge. The goal is to assess what is knowable from the provided text.\n",
    "* **Guiding Principle on Insight Relevance:** Not every provided Insight Card may be relevant to the specific strategic question. Use your judgment to select and apply only the insights that directly inform the identification of drivers, uncertainties, and potential impacts. It is not necessary to use every insight.\n",
    "* **Output Requirements:** The final report or presentation must contain:\n",
    "    * A clear definition of the policy from the provided Policy Card and the time horizon for the analysis.\n",
    "    * An identification of the key drivers of change and critical uncertainties, with full source citation.\n",
    "    * A set of 2-4 detailed, plausible, and distinct future scenario narratives.\n",
    "    * An analysis of the policy's performance, risks, and opportunities within each scenario.\n",
    "    * A set of recommended strategies, distinguishing between robust actions (valuable in all futures) and contingent actions (dependent on a specific future).\n",
    "    * A list of \"signposts\" or leading indicators to monitor which future is unfolding.\n",
    "    * A \"Follow-Up & Further Research\" section detailing information gaps.\n",
    "\n",
    "**3. Analytical Workflow & Rules**\n",
    "\n",
    "#### **Phase 1: Scoping and Identifying Drivers**\n",
    "\n",
    "* **1.1. Define the Analytical Scope and Time Horizon:**\n",
    "    * **Source Policy:** Reference the provided Policy Card.\n",
    "    * **Source Insights:** Reference the provided Insight Cards.\n",
    "    * **Time Horizon:** Define the time frame for the analysis (e.g., 5, 10, or 20 years). The time horizon should be long enough for significant changes to occur.\n",
    "* **1.2. Identify Key Drivers of Change:**\n",
    "    * **Rule:** Brainstorm a comprehensive list of external forces by extracting information directly from the provided source materials.\n",
    "    * **Guideline for using the Insight Cards:**\n",
    "        * Review the \"Comprehensive Explanation,\" \"Evidence FOR this Insight,\" and \"Author's Reasoning\" sections to identify established trends and forces.\n",
    "        * Review the \"Actionable Recommendations\" and \"Unanswered Questions\" sections to identify potential future pressures or developments.\n",
    "    * **Guideline for using the Policy Card:**\n",
    "        * Review the \"Summary\" and \"Arguments Against / Challenges\" sections to identify external pressures, dependencies, and potential obstacles.\n",
    "    * **Citation Requirement:** Every key driver, trend, or insight used must be cited in-line. The citation must be the specific alphanumeric location code found in the source materials (e.g., `RL32624_7__1` or `RL32624_111_122`). This ensures full traceability.\n",
    "* **1.3. Prioritize Critical Uncertainties:**\n",
    "    * **Rule:** From your list of drivers, select the **top two** most critical uncertainties to form the axes of your scenario framework. A driver is a \"critical uncertainty\" if it is both highly important and highly uncertain.\n",
    "    * **Guideline for Assessing Importance:** A driver is **important** if it is mentioned across multiple Insight Cards, or if the \"Arguments Against / Challenges\" section of the Policy Card or the \"Actionable Recommendations\" of an Insight Card suggest it has a major impact on the policy's success.\n",
    "    * **Guideline for Assessing Uncertainty:** A driver is **uncertain** if:\n",
    "        * It is framed as an \"Unanswered Question\" in an Insight Card.\n",
    "        * The \"Strength of This Specific Insight\" section indicates a low or medium confidence level.\n",
    "        * The Policy Card describes a key feature as \"Unclear\" or notes significant \"disagreements\" among stakeholders.\n",
    "        * An Insight Card explicitly identifies a dependency on an external event with an unknown outcome (e.g., \"depend... on outcomes from ongoing... negotiations\").\n",
    "\n",
    "#### **Phase 2: Scenario Development**\n",
    "\n",
    "* **2.1. Define Scenario Axes:**\n",
    "    * **Rule:** For each of the two Critical Uncertainties selected in Phase 1, define two plausible, extreme outcomes. These will form the axes for your scenarios.\n",
    "    * **Format:** List each uncertainty and its two opposing outcomes.\n",
    "\n",
    "    **Standard Axis Definition Format:**\n",
    "\n",
    "    * **Axis 1 - [Name of Critical Uncertainty 1]:**\n",
    "        * Outcome A: [Description of first extreme outcome]\n",
    "        * Outcome B: [Description of second extreme outcome]\n",
    "\n",
    "    * **Axis 2 - [Name of Critical Uncertainty 2]:**\n",
    "        * Outcome X: [Description of first extreme outcome]\n",
    "        * Outcome Y: [Description of second extreme outcome]\n",
    "\n",
    "    * **Guideline:** The four scenarios you develop will be based on the four possible combinations of these outcomes (A+X, B+X, A+Y, B+Y).\n",
    "* **2.2. Develop Scenario Narratives:**\n",
    "    * **Requirement:** For each of the four combinations, write a detailed and compelling narrative describing that future world. Give each scenario a memorable name that captures its essence.\n",
    "    * **Guideline for Grounding Narratives:** To build each narrative, synthesize the \"Comprehensive Explanation\" and \"Evidence\" sections from the Insight Cards. Imagine how those facts and descriptions would change or be emphasized in a world defined by that scenario's specific outcomes. This ensures the scenarios are extensions of the provided evidence.\n",
    "\n",
    "#### **Phase 3: Impact Analysis and Strategy Formulation**\n",
    "\n",
    "* **3.1. Stress-Test the Policy:**\n",
    "    * **Rule:** For each scenario narrative, analyze the performance of the policy outlined in the provided Policy Card.\n",
    "    * **Guideline for Structuring the Stress Test:** For each scenario, explicitly evaluate how the \"Arguments In Favor\" and \"Arguments Against / Challenges\" from the Policy Card would be amplified or diminished. Use the \"Actionable Recommendations or Implications\" from the Insight Cards as a checklist of potential impacts to consider. This directly links the impact analysis to the pre-identified arguments and implications.\n",
    "* **3.2. Identify Robust and Contingent Strategies:**\n",
    "    * **Requirement:** Based on the stress test, develop a set of strategic options.\n",
    "    * **Categorize Strategies:**\n",
    "        * **Robust Strategies:** High-priority actions that are beneficial across most or all scenarios.\n",
    "        * **Contingent Strategies:** Actions held in reserve, to be implemented only if evidence shows a specific scenario is emerging.\n",
    "* **3.3. Define Signposts:**\n",
    "    * For each scenario, identify a list of 3-5 \"signposts\" or leading indicators. These are early warning signals that suggest a particular scenario is becoming more likely.\n",
    "\n",
    "#### **Phase 4: Reporting and Monitoring**\n",
    "\n",
    "* **4.1. Structure the Strategic Report:**\n",
    "    * **Executive Summary:** Briefly describe the four scenarios and highlight the most critical strategic recommendations.\n",
    "    * **Introduction:** Define the source policy, time horizon, and the critical uncertainties used to build the scenarios.\n",
    "    * **Scenario Narratives:** Present the detailed story for each of the four futures.\n",
    "    * **Implications:** For each scenario, discuss the results of the stress test.\n",
    "    * **Strategic Options:** Detail the recommended robust and contingent strategies.\n",
    "    * **Monitoring Plan:** List the signposts to be tracked.\n",
    "\n",
    "#### **Phase 5: Follow-Up and Further Research**\n",
    "\n",
    "* **5.1. Document Information Gaps:**\n",
    "    * **Rule:** Explicitly list any areas where the analysis was limited due to missing information in the source documents. You must state what could not be completed and why.\n",
    "    * **Example:** \"The economic impact of Scenario 2 could not be fully assessed because the Policy Card lacks specific data on potential funding mechanisms (`RL32624_111_122`).\"\n",
    "* **5.2. Formulate Key Questions for Follow-Up:**\n",
    "    * **Rule:** Transform each documented information gap into a specific, actionable research question. This formalizes the \"Unanswered Questions\" identified in the source materials.\n",
    "    * **Example:** \"What are the three most likely funding mechanisms for 'Green Payments', and what is the estimated cost of each?\"\n",
    "* **5.3. Recommend Next Steps:**\n",
    "    * **Rule:** For each key question, recommend a concrete next step to obtain the missing information.\n",
    "    * **Example:** \"Recommend a targeted review of budget proposals from the last 5 years to identify precedents for funding similar environmental programs.\"\n",
    "\"\"\""
   ],
   "id": "aa70cbf1e78ea5c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for policy_document in tqdm(policy_documents):\n",
    "    strategy_analyses = list()\n",
    "    for _policy in tqdm(policy_document.variables['policy_insight_sources']):\n",
    "        strategic_analysis_prompt = strategic_analysis_guide_template.format(policy_card_text=_policy['policy_card'],\n",
    "                                         insight_cards_text=_policy['insight_card'],\n",
    "                                         source_card_text=_policy['source_cards'])\n",
    "        print(len(strategic_analysis_prompt.split(' ')))\n",
    "        strategic_analysis = call_llm_flash(strategic_analysis_prompt, temperature=0.2)\n",
    "        strategic_analysis_policy = deepcopy(_policy)\n",
    "        strategic_analysis_policy['analysis'] = strategic_analysis\n",
    "        strategy_analyses.append(strategic_analysis_policy)\n",
    "    policy_document.variables['strategy_analysis'] = strategy_analyses"
   ],
   "id": "36f35b8d718e9207",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "json_friendly = list()\n",
    "policy_document.__dict__.keys()"
   ],
   "id": "37af30d9ead725ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "json_policy_documents = list()\n",
    "for policy_document in tqdm(policy_documents):\n",
    "    policy_document_dict = deepcopy(policy_document.__dict__)\n",
    "    policy_document_dict['search_result'] = policy_document_dict['search_result'].to_json(orient='records')\n",
    "    policy_document_dict['policies'] = policy_document_dict['policies'].to_json(orient='records')\n",
    "    policy_document_dict['insights'] = policy_document_dict['insights'].to_json(orient='records')\n",
    "    policy_document_dict['passages'] = policy_document_dict['passages'].to_json(orient='records')\n",
    "    policy_document_dict['variables']['insight_chunks'] = policy_document_dict['variables']['insight_chunks'].to_json(orient='records')\n",
    "    json_policy_documents.append(policy_document_dict)"
   ],
   "id": "7ba3eb4865e2c5d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "policy_document.variables.keys()",
   "id": "290dba99db5879d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(research_json_folder.joinpath(f\"strategic_analysis_{query.replace(' ','_')}\"),'w') as f:\n",
    "    json.dump(json_policy_documents, f)"
   ],
   "id": "cf61702b18b9b105",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "policy_document.variables['strategy_analysis'][0].keys()",
   "id": "35d141904257ae51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(policy_document.variables['strategy_analysis'][0]['analysis'])",
   "id": "38a66beb2fd808b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "strategic_policy.keys()",
   "id": "55f5afc2ed17aee1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_strategies = list()\n",
    "for policy_document in policy_documents:\n",
    "    for strategic_policy in policy_document.variables['strategy_analysis']:\n",
    "        all_strategies.append(f\"\"\"**Policy Name:** {strategic_policy['policy']['policyName']}\n",
    "**Policy Type:** {strategic_policy['policy']['policyType']}\n",
    "**Policy Objective:** {strategic_policy['policy']['primaryObjective']}\n",
    "**Policy Details:** {strategic_policy['policy']['policyDetails']}\n",
    "\n",
    "**Policy Strategic Analysis:**\n",
    "{strategic_policy['analysis']}\"\"\".strip())"
   ],
   "id": "1984f9766f23b6e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len('\\n\\n----\\n\\n'.join(all_strategies).split(' '))",
   "id": "d5dd6bfaccb85c52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print('\\n----\\n'.join(all_strategies))",
   "id": "bca71e8d2727541",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(f\"test_{query.replace(' ','_')}_all_strategies.md\", 'w') as f:\n",
    "    f.write('\\n\\n-----\\n\\n'.join(all_strategies))"
   ],
   "id": "d7f5b7ca97c147dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "query",
   "id": "621c621832a156c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "52413090a1e0965",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
