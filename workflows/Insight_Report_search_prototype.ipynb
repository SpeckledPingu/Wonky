{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import lancedb\n",
    "from openai import OpenAI\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import pypandoc\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "load_dotenv('env_var')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import hashlib\n",
    "def hash_string_to_digits(input_string, num_digits=6):\n",
    "    \"\"\"Hashes a string to an 8-digit integer using SHA-256.\"\"\"\n",
    "    hashed_value = hashlib.sha256(input_string.encode('utf-8')).hexdigest()\n",
    "    return int(hashed_value, 16) % (10**num_digits)"
   ],
   "id": "9e8c65cf431fc4b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def format_evidence(evidence_list):\n",
    "    \"\"\"Formats the evidence list into a Markdown string.\"\"\"\n",
    "    markdown = \"\"\n",
    "    if len(evidence_list)==0:# or not isinstance(evidence_list, list):\n",
    "        return \"No evidence provided.\\n\"\n",
    "\n",
    "    for i, item in enumerate(evidence_list):\n",
    "        markdown += f\"  - **{item.get('Description', 'N/A')}**\\n\"\n",
    "        markdown += f\"    - **Key Data/Details:** {item.get('Key Data/Details', 'N/A')}\\n\"\n",
    "        markdown += f\"    - **Methodology Note:** {item.get('Methodology Note', 'N/A')}\\n\"\n",
    "        markdown += f\"    - **Source Note:** {item.get('Source Note', 'N/A')}\\n\"\n",
    "    return markdown\n",
    "\n",
    "\n",
    "def format_list(items, title):\n",
    "    \"\"\"Formats a simple list of strings into a Markdown list.\"\"\"\n",
    "    markdown = f\"#### *{title}*\\n\"\n",
    "    if len(items) == 0: # or not isinstance(items, list):\n",
    "        return markdown + \"- N/A\\n\"\n",
    "    for item in items:\n",
    "        markdown += f\"- {item}\\n\"\n",
    "    return markdown\n",
    "\n",
    "\n",
    "def generate_markdown(data):\n",
    "    \"\"\"\n",
    "    Generates a Markdown string from a list of insight objects.\n",
    "\n",
    "    Args:\n",
    "        data (list): A list of dictionaries, where each dictionary\n",
    "                     represents an insight.\n",
    "\n",
    "    Returns:\n",
    "        str: A string containing the formatted Markdown document.\n",
    "    \"\"\"\n",
    "    if not isinstance(data, list):\n",
    "        return \"Error: JSON data must be a list of insight objects.\"\n",
    "\n",
    "    full_markdown = \"\"\n",
    "    for i, insight in enumerate(data):\n",
    "        # --- Source Information ---\n",
    "        full_markdown += \"## Source Information\\n\"\n",
    "        full_markdown += f\"- **Original Source Title:** {insight.get('Original Source Title', 'N/A')}\\n\"\n",
    "        full_markdown += f\"- **Author(s) / Organization:** {insight.get('Author(s) / Organization', 'N/A')}\\n\"\n",
    "        full_markdown += f\"- **Location in Source:** {insight.get('Location in Source', 'N/A')}\\n\\n\"\n",
    "\n",
    "        # --- Comprehensive Explanation ---\n",
    "        full_markdown += \"## Comprehensive Explanation\\n\"\n",
    "        full_markdown += f\"{insight.get('Comprehensive Explanation of the Insight', 'N/A')}\\n\\n\"\n",
    "\n",
    "        # --- Evidence Section ---\n",
    "        full_markdown += \"## Evidence & Reasoning\\n\\n\"\n",
    "        full_markdown += \"### Evidence FOR this Insight\\n\"\n",
    "        full_markdown += format_evidence(insight.get('Evidence FOR this Insight'))\n",
    "        full_markdown += \"\\n\"\n",
    "\n",
    "        full_markdown += \"\"\"### Author's Reasoning FOR this Insight (The \"Why\")\\n\"\"\"\n",
    "        full_markdown += insight.get('''Author's Reasoning FOR this Insight (The \"Why\")''', 'N/A') + '\\n\\n'\n",
    "\n",
    "        full_markdown += \"\"\"### Evidence AGAINST or Contradicting this Insight\\n\"\"\"\n",
    "        full_markdown += f\"{insight.get('Evidence AGAINST or Contradicting this Insight', 'N/A')}\\n\\n\"\n",
    "\n",
    "        full_markdown += \"### Author's Reasoning AGAINST this Insight (or for the Nuance)\\n\"\n",
    "        full_markdown += insight.get('Author\\'s Reasoning AGAINST this Insight (or for the Nuance)', 'N/A') + \"\\n\\n\"\n",
    "        full_markdown += \"### Author's position on this insight:\\n\"\n",
    "        full_markdown += insight.get('Position Taken', 'N/A') + \"\\n\\n\"\n",
    "        # --- Strength of Insight ---\n",
    "        strength = insight.get('Strength of This Specific Insight', {})\n",
    "        full_markdown += \"## Strength of This Specific Insight\\n\"\n",
    "        full_markdown += f\"- **Assessment:** {strength.get('Assessment', 'N/A')}\\n\"\n",
    "        full_markdown += f\"- **Confidence Level:** {strength.get('Confidence Level', 'N/A')}\\n\"\n",
    "        full_markdown += f\"- **Common Sensibility:** {strength.get('Common Sensibility', 'N/A')}\\n\\n\"\n",
    "\n",
    "\n",
    "        # --- Actionable Recommendations ---\n",
    "        recommendations = insight.get('Actionable Recommendations or Implications', {})\n",
    "        full_markdown += \"## Actionable Recommendations or Implications\\n\"\n",
    "        full_markdown += f\"- **If this insight is true, it implies that we should:** {recommendations.get('If this insight is true, it implies that we should', 'N/A')}\\n\"\n",
    "        full_markdown += f\"- **This insight could be used in our project to:** {recommendations.get('This insight could be used in our project to', 'N/A')}\\n\\n\"\n",
    "        full_markdown += f\"- **If this insight is not true, it implies that we should:** {recommendations.get('If this insight is not true, it implies that we should', 'N/A')}\\n\\n\"\n",
    "\n",
    "        # --- Indexing ---\n",
    "        indexing = insight.get('Indexing for Future Reference', {})\n",
    "        full_markdown += \"## Indexing for Future Reference\\n\"\n",
    "        full_markdown += format_list(indexing.get('General Topics', []), \"General Topics\")\n",
    "        full_markdown += format_list(indexing.get('Specific Topics', []), \"Specific Topics\")\n",
    "        full_markdown += format_list(indexing.get('General Keywords', []), \"General Keywords\")\n",
    "        full_markdown += format_list(indexing.get('Specific Keywords', []), \"Specific Keywords\")\n",
    "        full_markdown += \"\\n\"\n",
    "\n",
    "        # --- Unanswered Questions ---\n",
    "        full_markdown += format_list(insight.get('Unanswered Questions', []), \"Unanswered Questions\")\n",
    "\n",
    "                # --- Main Title for the Insight ---\n",
    "        insight_hash = hash_string_to_digits(full_markdown, 6)\n",
    "        full_markdown = f\"## Insight: [INST{insight_hash}]\\n\\n### *{insight.get('Statement of the Insight', 'No Title Provided')}*\\n\\n\" + full_markdown\n",
    "\n",
    "        # --- Separator for next insight ---\n",
    "        if i < len(data) - 1:\n",
    "            full_markdown += \"\\n---\\n\\n\"\n",
    "\n",
    "    return full_markdown"
   ],
   "id": "e7045879becb5a46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def generate_insight_grounding_markdown(data, ids=None):\n",
    "    \"\"\"\n",
    "    Generates a Markdown string from a list of insight objects.\n",
    "\n",
    "    Args:\n",
    "        data (list): A list of dictionaries, where each dictionary\n",
    "                     represents an insight.\n",
    "\n",
    "    Returns:\n",
    "        str: A string containing the formatted Markdown document.\n",
    "    \"\"\"\n",
    "    if not isinstance(data, list):\n",
    "        return \"Error: JSON data must be a list of insight objects.\"\n",
    "\n",
    "    full_markdown = \"\"\n",
    "    for i, insight in enumerate(data):\n",
    "        # --- Main Title for the Insight ---\n",
    "        # full_markdown += f\"## Insight: \\n\\n### *{insight.get('Statement of the Insight', 'No Title Provided')}*\\n\\n\"\n",
    "\n",
    "        # --- Source Information ---\n",
    "        full_markdown += \"## Source Information\\n\"\n",
    "        full_markdown += f\"- **Original Source Title:** {insight.get('Original Source Title', 'N/A')}\\n\"\n",
    "        full_markdown += f\"- **Author(s) / Organization:** {insight.get('Author(s) / Organization', 'N/A')}\\n\"\n",
    "        full_markdown += f\"- **Location in Source:** {insight.get('Location in Source', 'N/A')}\\n\\n\"\n",
    "\n",
    "        # --- Comprehensive Explanation ---\n",
    "        full_markdown += \"## Comprehensive Explanation\\n\"\n",
    "        full_markdown += f\"{insight.get('Comprehensive Explanation of the Insight', 'N/A')}\\n\\n\"\n",
    "\n",
    "        # --- Evidence Section ---\n",
    "        full_markdown += \"## Evidence & Reasoning\\n\\n\"\n",
    "        full_markdown += \"### Evidence FOR this Insight\\n\"\n",
    "        full_markdown += format_evidence(insight.get('Evidence FOR this Insight'))\n",
    "        full_markdown += \"\\n\"\n",
    "\n",
    "        full_markdown += \"\"\"### Author's Reasoning FOR this Insight (The \"Why\")\\n\"\"\"\n",
    "        full_markdown += insight.get('''Author's Reasoning FOR this Insight (The \"Why\")''', 'N/A') + '\\n\\n'\n",
    "\n",
    "        full_markdown += \"\"\"### Evidence AGAINST or Contradicting this Insight\\n\"\"\"\n",
    "        full_markdown += f\"{insight.get('Evidence AGAINST or Contradicting this Insight', 'N/A')}\\n\\n\"\n",
    "\n",
    "        full_markdown += \"### Author's Reasoning AGAINST this Insight (or for the Nuance)\\n\"\n",
    "        full_markdown += insight.get('Author\\'s Reasoning AGAINST this Insight (or for the Nuance)', 'N/A') + \"\\n\\n\"\n",
    "        full_markdown += \"### Author's position on this insight:\\n\"\n",
    "        full_markdown += insight.get('Position Taken', 'N/A') + \"\\n\\n\"\n",
    "        # --- Strength of Insight ---\n",
    "        strength = insight.get('Strength of This Specific Insight', {})\n",
    "        full_markdown += \"## Strength of This Specific Insight\\n\"\n",
    "        full_markdown += f\"- **Assessment:** {strength.get('Assessment', 'N/A')}\\n\"\n",
    "        full_markdown += f\"- **Confidence Level:** {strength.get('Confidence Level', 'N/A')}\\n\"\n",
    "        full_markdown += f\"- **Common Sensibility:** {strength.get('Common Sensibility', 'N/A')}\\n\\n\"\n",
    "\n",
    "        # --- Actionable Recommendations ---\n",
    "        recommendations = insight.get('Actionable Recommendations or Implications', {})\n",
    "        full_markdown += \"## Actionable Recommendations or Implications\\n\"\n",
    "        full_markdown += f\"- **If this insight is true, it implies that we should:** {recommendations.get('If this insight is true, it implies that we should', 'N/A')}\\n\"\n",
    "        full_markdown += f\"- **This insight could be used in our project to:** {recommendations.get('This insight could be used in our project to', 'N/A')}\\n\\n\"\n",
    "        full_markdown += f\"- **If this insight is not true, it implies that we should:** {recommendations.get('If this insight is not true, it implies that we should', 'N/A')}\\n\\n\"\n",
    "\n",
    "        # --- Unanswered Questions ---\n",
    "        full_markdown += format_list(insight.get('Unanswered Questions', []), \"Unanswered Questions\")\n",
    "\n",
    "        # --- Main Title for the Insight ---\n",
    "        if ids is None:\n",
    "            insight_hash = hash_string_to_digits(full_markdown, 6)\n",
    "            insight_citation = f\"INST{insight_hash}\"\n",
    "        else:\n",
    "            insight_citation = ids[i]\n",
    "        full_markdown = f\"## Insight: [{insight_citation}]\\n\\n### *{insight.get('Statement of the Insight', 'No Title Provided')}*\\n\\n\" + full_markdown\n",
    "\n",
    "\n",
    "        # --- Separator for next insight ---\n",
    "        if i < len(data) - 1:\n",
    "            full_markdown += \"\\n---\\n\\n\"\n",
    "\n",
    "    return full_markdown"
   ],
   "id": "777d6c557e9edc56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "from copy import deepcopy\n",
    "\n",
    "project_folder = Path('insight_research')\n",
    "project_folder.mkdir(parents=True, exist_ok=True)\n",
    "research_json_folder = project_folder.joinpath('json_data')\n",
    "research_json_folder.mkdir(parents=True, exist_ok=True)\n",
    "database_location = project_folder.joinpath('research.sqlite')\n",
    "\n",
    "conn = sqlite3.connect(database_location)\n",
    "cursor = conn.cursor()"
   ],
   "id": "7441465f241d1c92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "index = lancedb.connect('../wonky_data/indexes/')\n",
    "table = index.open_table('sections_hybrid')\n",
    "encoder = SentenceTransformer('nomic-ai/nomic-embed-text-v1.5', device='mps',trust_remote_code=True)"
   ],
   "id": "9ca7d02a6be9743f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "def call_llm(query, temperature=0.35, seed=42, model=\"gemma-3-12b-it-qat\"):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        seed=seed,\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "model = \"gemini-2.0-flash\"\n",
    "total_tokens = list()\n",
    "\n",
    "def call_llm_flash(query, temperature=0.1, seed=42, max_tokens=7500 ):\n",
    "    client = genai.Client(api_key=os.environ['GEMINI_API_KEY'])\n",
    "    retries = 3\n",
    "    time_delay = 15\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=model,\n",
    "                contents=[query],\n",
    "                config=types.GenerateContentConfig(\n",
    "                    max_output_tokens=max_tokens,\n",
    "                    temperature=temperature,\n",
    "                    seed=seed\n",
    "                )\n",
    "            )\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"Retries left: {retries - i}\")\n",
    "            time.sleep(time_delay)\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "    total_tokens.append({'prompt_tokens':response.usage_metadata.prompt_token_count,\n",
    "                         'completion_tokens':response.usage_metadata.candidates_token_count,\n",
    "                         'total_tokens':response.usage_metadata.total_token_count,\n",
    "                         'timestamp':datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")})\n",
    "\n",
    "    return response.text\n",
    "\n",
    "def convert_df_sections_to_list(sections):\n",
    "    section_list = sections.explode().to_list()\n",
    "    section_list = convert_all_sections(section_list)\n",
    "    return section_list\n",
    "\n",
    "def convert_sections_to_dict(section):\n",
    "    converted_sections = list()\n",
    "    parts = section.replace(\"\\'\",'\"').split('\", ')\n",
    "    for _part in parts:\n",
    "        _part = _part + '\"}'\n",
    "        # print(_part)\n",
    "        _part = re.findall(r\"\"\"^{?(.*?): \"(.*?)}$\"\"\",_part, flags=re.DOTALL | re.MULTILINE)\n",
    "\n",
    "        formatted_parts = {int(_part[0][0].strip('\"} ')): _part[0][1].strip('\"} \\n')}\n",
    "        converted_sections.append(formatted_parts)\n",
    "    return converted_sections\n",
    "\n",
    "def convert_all_sections(sections):\n",
    "    extracted_sections = list()\n",
    "    for _section in sections:\n",
    "        section = convert_sections_to_dict(_section)\n",
    "        extracted_sections.extend(section)\n",
    "    return extracted_sections"
   ],
   "id": "e741d92533bb1d06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def parse_data_for_chroma(data):\n",
    "    _metadata = list()\n",
    "    _vectors = list()\n",
    "    _documents = list()\n",
    "    for _row in data:\n",
    "        _metadata.append({k:v for k, v in _row.items() if k not in ['extraction_text','vector']})\n",
    "        _vectors.append(_row['vector'])\n",
    "        _documents.append(_row['extraction_text'])\n",
    "    return _metadata, _vectors, _documents"
   ],
   "id": "c21993df7548f99a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Set variables",
   "id": "e9cb11d39ef3ef10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "subject_matter = \"Rural Broadband in the United States\"\n",
    "focus = \"Barriers and opportunities to improve access\"\n",
    "depth_to_search = 50\n",
    "max_documents = 5\n",
    "research_id = hash_string_to_digits(f\"\"\"{subject_matter} : {focus}\"\"\")\n",
    "with open(research_json_folder.joinpath('insights_181400.json'),'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "insight_index = lancedb.connect(project_folder.joinpath('insight_index'))\n",
    "if 'insights' in insight_index.table_names():\n",
    "    insight_index.drop_table('insights')\n",
    "insight_table = insight_index.create_table('insights', data)"
   ],
   "id": "e5147f9c4cfa6f08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "query = \"Rural broadband expansion initiatives.\"\n",
    "query_vec = encoder.encode(query)"
   ],
   "id": "92692737f8c5abf5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "results = insight_table.search(query_vec).distance_type('cosine').limit(25).to_pandas()\n",
    "results['insight_id'] = results['extraction_text'].apply(lambda x: f\"INST{hash_string_to_digits(x, 6)}\")\n",
    "results"
   ],
   "id": "916de53b9dfbe202",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "insights = list()\n",
    "insight_texts = list()\n",
    "for index, row in results.iterrows():\n",
    "    insights.append(row['insights']['insight'])\n",
    "    insight_texts.append(generate_insight_grounding_markdown([row['extraction_details']], [row['insight_id']]))\n",
    "insight_text = '\\n\\n----\\n\\n'.join(insight_texts)\n",
    "len(insight_text.split(' '))"
   ],
   "id": "50e9742c2ff2ff4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "insight_text",
   "id": "504bf2fdb89ecf8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(project_folder.joinpath('relevant_insights.md'),'w') as f:\n",
    "    f.write(insight_text)"
   ],
   "id": "32c09e9fd1d15335",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(project_folder.joinpath('relevant_insight_single.md'),'w') as f:\n",
    "    f.write(insight_texts[0])"
   ],
   "id": "c516ea73cc37edee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_listlike_policy_analysis_prompt(question: str, insights: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "You are an expert junior public policy analyst. Your task is to answer a specific policy question based *only* on the provided 'insights'. You must follow these rules meticulously:\n",
    "\n",
    "**THE CARDINAL RULE: CITE EVERY CLAIM**\n",
    "This is the most important rule. You must add a citation to every single piece of information you write. Every sentence, every clause, and every data point you pull from an insight document must be followed by its citation key in brackets (e.g., [INST123456]). If multiple insights support a single claim, list them in the same brackets, separated by a comma (e.g., [INST123456, INST987654]). Do not cite a claim at the end of a sentence if the beginning of the sentence makes a different claim; cite each claim individually.\n",
    "\n",
    "**YOUR STEP-BY-STEP WORKFLOW**\n",
    "1.  **Understand the Question:** Read the user's policy question to understand what you need to answer.\n",
    "2.  **Analyze Insights:** Carefully read the provided insights to find all relevant information.\n",
    "3.  **Map Information:** For each piece of information, determine where it belongs in the template (Supporting Evidence, Contradictory Evidence, Context, etc.).\n",
    "4.  **Condense and Rephrase:** Do not copy-paste from the insights. Rewrite the information concisely in your own words without changing the original meaning.\n",
    "5.  **Fill the Template:** Populate the template below with the rephrased information, ensuring every single claim is cited.\n",
    "6.  **Write the Summary Last:** After completing all other sections, write a brief executive summary that directly answers the question, again citing every claim.\n",
    "7.  **Output Format:** Your final output must be in Markdown format, following the structure of the template exactly.\n",
    "\n",
    "---\n",
    "**INPUTS**\n",
    "\n",
    "**Policy Question:** \"{question}\"\n",
    "\n",
    "**Provided Insights:**\n",
    "\\\"\\\"\\\"\n",
    "{insights}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "---\n",
    "**OUTPUT TEMPLATE (Use this exact structure for your response)**\n",
    "\n",
    "## Public Policy Analysis Response\n",
    "\n",
    "**Question Being Addressed:** {question}\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Executive Summary\n",
    "\n",
    "* [Provide a 1-3 sentence direct answer to the question, summarizing your most critical findings. Remember to cite every claim.]\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Detailed Findings\n",
    "\n",
    "#### A. Supporting Evidence / Reasons For\n",
    "\n",
    "* **Finding 1:** [State the first piece of supporting evidence and add its citation.]\n",
    "* **Finding 2:** [State the next piece of supporting evidence and add its citation.]\n",
    "* ...\n",
    "\n",
    "#### B. Contradictory Evidence / Reasons Against\n",
    "\n",
    "* **Finding 1:** [State the first piece of contradictory evidence and add its citation.]\n",
    "* ...\n",
    "\n",
    "#### C. Context and Nuance\n",
    "\n",
    "* **Point 1:** [Explain relevant context, author's reasoning, or other nuances and add its citation.]\n",
    "* ...\n",
    "\n",
    "#### D. Identified Gaps & Unanswered Questions\n",
    "\n",
    "* **Gap 1:** [State a key piece of information that is missing from the insight and add its citation.]\n",
    "* ...\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Strength of Evidence Assessment\n",
    "\n",
    "* **Evidence Quality:** [State the insight's qualitative assessment of the evidence (e.g., 'strong', 'weak') and add citation.]\n",
    "* **Evidence Support:** [Describe how the evidence supports the insight (e.g., 'directly supportive', 'provides examples') and add citation.]\n",
    "* **Confidence Level:** [State the specific confidence level indicated (e.g., 'High', 'Medium', 'Low') and add citation.]\n",
    "\"\"\"\n",
    "    return prompt"
   ],
   "id": "4a429344648e100d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_senior_analyst_briefing_prompt(question: str, insights: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "You are an expert senior policy analyst. Your task is to synthesize the provided 'insights' into a concise and comprehensive briefing memo that addresses a central policy question. Your audience consists of other experts and decision-makers who require a rapid, high-level understanding of the issue, its evidence base, and its strategic implications.\n",
    "\n",
    "**Core Directives:**\n",
    "1.  **Synthesize and Group Thematically:** Do not simply list findings. Synthesize related pieces of information into thematic, analytical points. Group findings, points, and identified gaps by their common topic or subject matter to create a cohesive narrative.\n",
    "2.  **Maintain Rigorous Citation:** Every factual claim, data point, or piece of evidence must be meticulously cited. Use bracketed citations (e.g., [INST123456]). If multiple sources support a point, cite them all (e.g., [INST123456, INST987654]).\n",
    "3.  **Adopt an Analytical Tone:** The memo should be objective, concise, and focused on the \"so what.\" The language should be professional and direct.\n",
    "4.  **Structure is Key:** Adhere strictly to the briefing memo template provided below. The structure is designed to facilitate quick comprehension by a senior audience.\n",
    "\n",
    "---\n",
    "**INPUTS**\n",
    "\n",
    "**Core Topic/Question:** \"{question}\"\n",
    "\n",
    "**Provided Insights for Synthesis:**\n",
    "\\\"\\\"\\\"\n",
    "{insights}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "---\n",
    "**OUTPUT TEMPLATE: BRIEFING MEMO**\n",
    "\n",
    "**SUBJECT:** Briefing on: {question}\n",
    "\n",
    "### 1. Executive Summary & Key Judgments\n",
    "\n",
    "* **Top-Line Synthesis:** [Provide a 2-3 sentence summary that synthesizes the most critical information and directly addresses the core topic. Every claim must be cited.]\n",
    "* **Key Judgments:** [Use 2-4 bullet points to state the most significant analytical conclusions drawn from the evidence. These are not just facts, but interpretations of the facts. Every judgment must be supported by a citation.]\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Thematic Analysis of Findings\n",
    "\n",
    "*[This section replaces a simple list of evidence. Group related findings from all insights into themes.]*\n",
    "\n",
    "* **Theme 1:** [Name the first analytical theme (e.g., \"Programmatic Evolution,\" \"Evidence of Inefficiency\").]\n",
    "    * [Synthesize all supporting and contradictory evidence for this theme from one or more insights, ensuring every claim is cited.]\n",
    "* **Theme 2:** [Name the second analytical theme (e.g., \"Contradictory Outcomes,\" \"Geographic Disparities\").]\n",
    "    * [Synthesize all supporting and contradictory evidence for this theme, citing every claim.]\n",
    "* ...\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Assessment of Evidence Base\n",
    "\n",
    "*[This section summarizes the overall quality of the evidence from the provided insights.]*\n",
    "\n",
    "* **The Good (Reliable & Clear):** [Summarize the strengths of the evidence base. What is well-documented, directly supportive, or based on high-quality sources? [CITE RELEVANT SOURCES].]\n",
    "* **The Bad (Contradictory & Weak):** [Summarize the weaknesses of the evidence base. Are there direct contradictions between sources or poorly supported claims? [CITE RELEVANT SOURCES].]\n",
    "* **The Questionable (Gaps & Ambiguities):** [Summarize the most critical gaps, under-explained points, or unanswered questions that prevent a complete analysis. Group related gaps by topic. [CITE SOURCES THAT REVEAL THE GAPS].]\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Strategic Implications & Considerations\n",
    "\n",
    "* **For Current Policy:** [Based on the analysis, what are the direct implications for current policy or operations? [CITE THE SUPPORTING EVIDENCE].]\n",
    "* **For Future Analysis:** [What are the key considerations or questions that need to be addressed in future analytical work? [CITE THE SUPPORTING EVIDENCE].]\n",
    "\"\"\"\n",
    "#     prompt = f\"\"\"\n",
    "# You are an expert senior policy analyst. Your task is to synthesize the provided 'insights' into a concise and comprehensive briefing memo that addresses a central policy question. Your audience consists of other experts and decision-makers who require a rapid, high-level understanding of the issue, its evidence base, and its strategic implications.\n",
    "#\n",
    "# **Core Directives:**\n",
    "# 1.  **Synthesize, Don't List:** Do not simply list findings from the insights. Synthesize them into thematic, analytical points. Connect related pieces of information, even if they come from different insights.\n",
    "# 2.  **Maintain Rigorous Citation:** Every factual claim, data point, or piece of evidence must be meticulously cited. Use bracketed citations (e.g., [INST123456]). If multiple sources support a point, cite them all (e.g., [INST123456, INST987654]).\n",
    "# 3.  **Adopt an Analytical Tone:** The memo should be objective, concise, and focused on the \"so what.\" The language should be professional and direct.\n",
    "# 4.  **Structure is Key:** Adhere strictly to the briefing memo template provided below. The structure is designed to facilitate quick comprehension by a senior audience.\n",
    "#\n",
    "# ---\n",
    "# **INPUTS**\n",
    "#\n",
    "# **Core Topic/Question:** \"{question}\"\n",
    "#\n",
    "# **Provided Insights for Synthesis:**\n",
    "# \\\"\\\"\\\"\n",
    "# {insights}\n",
    "# \\\"\\\"\\\"\n",
    "#\n",
    "# ---\n",
    "# **OUTPUT TEMPLATE: BRIEFING MEMO**\n",
    "#\n",
    "# **SUBJECT:** Briefing on: {question}\n",
    "#\n",
    "# ### 1. Executive Summary & Key Judgments\n",
    "#\n",
    "# * **Top-Line Synthesis:** [Provide a 2-3 sentence summary that synthesizes the most critical information and directly addresses the core topic. Every claim must be cited.]\n",
    "# * **Key Judgments:** [Use 2-4 bullet points to state the most significant analytical conclusions drawn from the evidence. These are not just facts, but interpretations of the facts. Every judgment must be supported by a citation.]\n",
    "#\n",
    "# ---\n",
    "#\n",
    "# ### 2. Thematic Analysis of Findings\n",
    "#\n",
    "# *[This section replaces a simple list of evidence. Group related findings into themes.]*\n",
    "#\n",
    "# * **Theme 1:** [Name the first analytical theme (e.g., \"Programmatic Evolution,\" \"Evidence of Inefficiency\").]\n",
    "#     * [Synthesize the supporting evidence for this theme from one or more insights, ensuring every claim is cited.]\n",
    "# * **Theme 2:** [Name the second analytical theme (e.g., \"Contradictory Outcomes,\" \"Data and Measurement Gaps\").]\n",
    "#     * [Synthesize the supporting evidence for this theme, citing every claim.]\n",
    "# * ...\n",
    "#\n",
    "# ---\n",
    "#\n",
    "# ### 3. Assessment of Evidence Base\n",
    "#\n",
    "# * **Overall Quality:** [Provide a holistic assessment of the quality of the evidence presented across all insights. Comment on its strengths (e.g., 'based on primary government data') and weaknesses (e.g., 'lacks recent information') [CITE ALL RELEVANT SOURCES].]\n",
    "# * **Key Gaps Identified:** [Summarize the most critical unanswered questions or gaps in the provided information that prevent a complete analysis [CITE SOURCES THAT REVEAL THE GAPS].]\n",
    "#\n",
    "# ---\n",
    "#\n",
    "# ### 4. Strategic Implications & Considerations\n",
    "#\n",
    "# * **For Current Policy:** [Based on the analysis, what are the direct implications for current policy or operations? [CITE THE SUPPORTING EVIDENCE].]\n",
    "# * **For Future Analysis:** [What are the key considerations or questions that need to be addressed in future analytical work? [CITE THE SUPPORTING EVIDENCE].]\n",
    "#\n",
    "# ---\n",
    "#\n",
    "# ### 5. Source Reference Log\n",
    "#\n",
    "# * [List all Insight IDs used to generate this report.]\n",
    "#\n",
    "# \"\"\"\n",
    "    return prompt"
   ],
   "id": "4c7193ad026a1c3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "policy_analysis_prompt = create_senior_analyst_briefing_prompt(query, insight_text)\n",
    "len(policy_analysis_prompt.split(' '))"
   ],
   "id": "2bd82be9e7d5818f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "policy_analysis = call_llm_flash(policy_analysis_prompt, temperature=0.1)",
   "id": "89270b79e7b7cda0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(project_folder.joinpath('insight_analysis.md'),'w') as f:\n",
    "    f.write(policy_analysis)"
   ],
   "id": "a11195164bc984f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "policy_analysis_local = call_llm(policy_analysis_prompt, temperature=0.1, model='google/gemma-3-4b')",
   "id": "d160c4f15dc9f914",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(project_folder.joinpath('insight_analysis_local.md'),'w') as f:\n",
    "    f.write(policy_analysis_local)"
   ],
   "id": "d5d8f96131cb8748",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Insight citation mapping",
   "id": "2bdfc5c764893d27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "footnote_analysis = policy_analysis",
   "id": "d5d4c0c24ed53ab2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "analysis_citations = list()\n",
    "for _citation in re.findall(r\"(INST\\d+)(?:\\]|, )|\\[(INST\\d+)(?:\\]|, )\", footnote_analysis):\n",
    "    if _citation[0]:\n",
    "        if _citation[0] not in analysis_citations:\n",
    "            analysis_citations.append(_citation[0])\n",
    "    elif _citation[1]:\n",
    "        if _citation[1] not in analysis_citations:\n",
    "            analysis_citations.append(_citation[1])\n",
    "    else:\n",
    "        continue"
   ],
   "id": "65dc807240e10ffd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for _citation in analysis_citations:\n",
    "    if _citation not in results['insight_id'].to_list():\n",
    "        print(_citation)\n",
    "footnote_lookup = {i:_citation for i,_citation in enumerate(analysis_citations, start=1)}\n",
    "len(analysis_citations)"
   ],
   "id": "e721806f23160ebc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "footnote_text = list()\n",
    "for i, _citation in sorted(footnote_lookup.items(), key=lambda x: x[0]):\n",
    "    footnote_analysis = re.sub(fr\"({footnote_lookup[i]})\", f'[^{i}]', footnote_analysis)\n",
    "    footnote_text.append(f'[^{i}]: {_citation}')\n",
    "footnote_text = '\\n'.join(footnote_text)\n",
    "footnote_analysis += f\"\\n\\n{footnote_text}\"\n",
    "footnote_analysis = re.sub(r'(\\[+)', r'[', footnote_analysis)\n",
    "footnote_analysis = re.sub(r'(\\]+)', r']', footnote_analysis)\n",
    "with open(project_folder.joinpath('insight_analysis_w_footnotes.md'),'w') as f:\n",
    "    f.write(footnote_analysis)"
   ],
   "id": "73fff89d24c750f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "footnote_analysis_latex = pypandoc.convert_text(footnote_analysis, to='latex', format='markdown')\n",
    "footnote_analysis_latex = footnote_analysis_latex.replace('subsection','subsection*')\n",
    "latex_header = r\"\"\"\\documentclass{article}\n",
    "\\usepackage{graphicx} % Required for inserting images\n",
    "\\usepackage[para]{footmisc}\n",
    "\n",
    "\\title{Policy insights}\n",
    "\\author{James Littiebrant}\n",
    "\\date{June 2025}\n",
    "\n",
    "\\begin{document}\n",
    "\n",
    "\\maketitle\"\"\"\n",
    "latex_footer = r\"\"\"\n",
    "\\end{document}\"\"\"\n",
    "footnote_analysis_latex = latex_header + '\\n\\n' + footnote_analysis_latex + '\\n\\n' + latex_footer\n",
    "with open(project_folder.joinpath(\"insight_analysis_latex.tex\"),\"w\") as f:\n",
    "    f.write(footnote_analysis_latex)"
   ],
   "id": "5f6f4d25f4a423c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Source Traceback",
   "id": "586ebeadffd1ddb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "source_trace_back = policy_analysis",
   "id": "9b59236310f0dfb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results",
   "id": "d54033d488780420",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "source_document_lookup = dict()\n",
    "for index, row in results.iterrows():\n",
    "    source_document_lookup[row['insight_id']] = row['id']\n",
    "\n",
    "for _insight_id, _id in source_document_lookup.items():\n",
    "    source_trace_back = source_trace_back.replace(_insight_id, _id)"
   ],
   "id": "7527467fb3281fe1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "source_citations = list()\n",
    "for _citation in re.findall(r\"(\\w+\\d+)(?:\\]|, )|\\[(\\w+\\d+)(?:\\]|, )\", source_trace_back):\n",
    "    if _citation[0]:\n",
    "        if _citation[0] not in source_citations:\n",
    "            source_citations.append(_citation[0])\n",
    "    elif _citation[1]:\n",
    "        if _citation[1] not in source_citations:\n",
    "            source_citations.append(_citation[1])\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "for _citation in source_citations:\n",
    "    if _citation not in results['insight_id'].to_list():\n",
    "        print(_citation)\n",
    "source_footnote_lookup = {i:_citation for i,_citation in enumerate(source_citations, start=1)}"
   ],
   "id": "b993b72cf86e85f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "source_footnote_text = list()\n",
    "for i, _citation in sorted(source_footnote_lookup.items(), key=lambda x: x[0]):\n",
    "    source_trace_back = re.sub(fr\"({source_footnote_lookup[i]})\", f'[^{i}]', source_trace_back)\n",
    "    source_footnote_text.append(f'[^{i}]: {_citation}')\n",
    "source_footnote_text = '\\n'.join(source_footnote_text)\n",
    "source_trace_back += f\"\\n\\n{source_footnote_text}\"\n",
    "source_trace_back = re.sub(r'(\\[+)', r'[', source_trace_back)\n",
    "source_trace_back = re.sub(r'(\\]+)', r']', source_trace_back)\n",
    "with open(project_folder.joinpath('insight_analysis_w_source_footnotes.md'),'w') as f:\n",
    "    f.write(source_trace_back)"
   ],
   "id": "7ace75e0b73e8c21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "source_footnote_analysis_latex = pypandoc.convert_text(source_trace_back, to='latex', format='markdown')\n",
    "source_footnote_analysis_latex = source_footnote_analysis_latex.replace('subsection','subsection*')\n",
    "latex_header = r\"\"\"\\documentclass{article}\n",
    "\\usepackage{graphicx} % Required for inserting images\n",
    "\\usepackage[para]{footmisc}\n",
    "\n",
    "\\title{Policy insights}\n",
    "\\author{James Littiebrant}\n",
    "\\date{June 2025}\n",
    "\n",
    "\\begin{document}\n",
    "\n",
    "\\maketitle\"\"\"\n",
    "latex_footer = r\"\"\"\n",
    "\\end{document}\"\"\"\n",
    "source_footnote_analysis_latex = latex_header + '\\n\\n' + source_footnote_analysis_latex + '\\n\\n' + latex_footer\n",
    "with open(project_folder.joinpath(\"insight_analysis_source_latex.tex\"),\"w\") as f:\n",
    "    f.write(source_footnote_analysis_latex)"
   ],
   "id": "2450a602333c8e87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a2d719a9f66043fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Source Passage Traceback",
   "id": "483bb9a1fa66ddef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "source_passage_trace_back = policy_analysis",
   "id": "b16205dca6dbba14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results",
   "id": "c78aadf775de038b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def format_subsection_citations(citation):\n",
    "    return f\"{citation[0]}({citation[1]})({citation[2]})\"\n",
    "\n",
    "source_document_lookup = dict()\n",
    "for index, row in results.iterrows():\n",
    "    source_section = re.findall(r'([a-zA-Z\\d]+?)__(\\d+)___(\\d+)', '|'.join(row['insights']['location']))\n",
    "    source_section = [format_subsection_citations(x) for x in source_section]\n",
    "    source_section = ', '.join(source_section)\n",
    "    source_document_lookup[row['insight_id']] = source_section\n",
    "\n",
    "for _insight_id, _id in source_document_lookup.items():\n",
    "    source_passage_trace_back = source_passage_trace_back.replace(_insight_id, _id)"
   ],
   "id": "282da8cfe8c1b36a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "source_passage_citations = list()\n",
    "_citation_track = list()\n",
    "for _citation in source_document_lookup.values():\n",
    "    if _citation in _citation_track:\n",
    "        continue\n",
    "    _re_citation = _citation.replace('(','\\(').replace(')','\\)')\n",
    "    if re.search(_re_citation, source_passage_trace_back):\n",
    "        _citation_span = re.search(_re_citation, source_passage_trace_back).span(0)[0]\n",
    "        source_passage_citations.append((_citation_span, _citation))\n",
    "        _citation_track.append(_citation)\n",
    "source_passage_citations = sorted(source_passage_citations, key=lambda x: x[0])\n",
    "source_passage_citations = [x[1] for x in source_passage_citations]\n",
    "source_passage_footnote_lookup = {i:_citation for i,_citation in enumerate(source_passage_citations, start=1)}"
   ],
   "id": "c3f02ff793bab817",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "source_passage_footnote_lookup",
   "id": "e4cc8f6ce531d4a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "source_footnote_text = list()\n",
    "for i, _citation in sorted(source_passage_footnote_lookup.items(), key=lambda x: x[0]):\n",
    "    _re_citation = _citation.replace('(','\\(').replace(')','\\)')\n",
    "    source_passage_trace_back = re.sub(fr\"({_re_citation})\", f'[^{i}]', source_passage_trace_back)\n",
    "    source_footnote_text.append(f'[^{i}]: {_citation}')\n",
    "source_footnote_text = '\\n'.join(source_footnote_text)\n",
    "\n",
    "source_passage_trace_back += f\"\\n\\n{source_footnote_text}\"\n",
    "source_passage_trace_back = re.sub(r'(\\[+)', r'[', source_passage_trace_back)\n",
    "source_passage_trace_back = re.sub(r'(\\]+)', r']', source_passage_trace_back)\n",
    "with open(project_folder.joinpath('insight_analysis_w_source_passage_footnotes.md'),'w') as f:\n",
    "    f.write(source_passage_trace_back)"
   ],
   "id": "1710ca4277d34895",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "source_passage_footnote_analysis_latex = pypandoc.convert_text(source_passage_trace_back, to='latex', format='markdown')\n",
    "source_passage_footnote_analysis_latex = source_passage_footnote_analysis_latex.replace('subsection','subsection*')\n",
    "latex_header = r\"\"\"\\documentclass{article}\n",
    "\\usepackage{graphicx} % Required for inserting images\n",
    "\\usepackage[para]{footmisc}\n",
    "\n",
    "\\title{Policy insights}\n",
    "\\author{James Littiebrant}\n",
    "\\date{June 2025}\n",
    "\n",
    "\\begin{document}\n",
    "\n",
    "\\maketitle\"\"\"\n",
    "latex_footer = r\"\"\"\n",
    "\\end{document}\"\"\"\n",
    "source_passage_footnote_analysis_latex = latex_header + '\\n\\n' + source_passage_footnote_analysis_latex + '\\n\\n' + latex_footer\n",
    "with open(project_folder.joinpath(\"insight_analysis_source_passage_latex.tex\"),\"w\") as f:\n",
    "    f.write(source_passage_footnote_analysis_latex)"
   ],
   "id": "8ea17b92ae1bac57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "__ = pypandoc.convert_text(source_passage_footnote_analysis_latex, to='docx', format='latex', outputfile=project_folder.joinpath('word_doc_test.docx'))",
   "id": "4845d02329f544f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pypandoc.convert_text?",
   "id": "98cc8658d9243c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b34eb1894d1be242",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
